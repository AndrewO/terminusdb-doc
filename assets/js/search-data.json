{
  
  "1": {
    "title": "Administration",
    "content": "Deployment options | Backup / restore | Security | Deployment options . The recommend way of running TerminusDB is to use terminusdb-quickstart. . To use terminusdb-quickstart you need to have Git and Docker installed, then you can clone the terminusdb-quickstart repo and run the server by following the instructions in the README.md on GitHub: . https://github.com/terminusdb/terminusdb-quickstart/blob/master/README.md . git clone https://github.com/terminusdb/terminusdb-quickstart cd ./terminusdb-quickstart ./terminusdb-container run . Experienced users can use the Docker container in their own configuration, or compile from source code. . The TerminusDB Docker container is available on Docker Hub: . https://hub.docker.com/r/terminusdb/terminusdb-server . Source code and compilation instructions can be found in the terminusdb/terminusdb-server repo on github: . https://github.com/terminusdb/terminusdb-server . Backup / restore . Backing up is as simple as pushing your data to a remote on TerminusDB Hub. You can run TerminusDB on a different machine as well and use it as a backup remote. . Restoring the database can be done by pulling from the remote. . Users of Docker or terminusdb-quickstart will be able to backup the data by backing their Docker volumes. . Security . Always change the default password! | If you want to host your instance of TerminusDB, put it behind a reverse proxy with HTTPS | .",
    "url": "/docs/administration/",
    "relUrl": "/administration/"
  }
  ,"2": {
    "title": "Advanced Topics",
    "content": "Advanced Topics - OWL Unleashed . . Introduction | Scoping | Boxing Datatypes | Open and Closed World Reasoning Inference Graph | | Freestyle OWL | . Introduction . TerminusDB supports a large fragment of the OWL language. This enables a large number of complex constraints to be expressed in a wide variety of different ways. However, as OWL supports multiple inheritance, it is almost never necessary to use anything much more esoteric than subclassing to achieve a desired effect. This section demonstrates how we can solve some common data-modelling problems with TerminusDB. . Scoping . When we construct knowledge graphs, consisting of relationships between things, we often want to scope the relationships, or the properties of the things, especially by time. In a more general sense, the relationships between things are often complex and can’t be represented by a simple property. In TerminusDB this is easy to achieve by creating classes to represent the common properties. . For example, if we wanted to model a situation where a person was a shareholder of a company for a certain period of time. We want our knowledge graph to contain a shareholder relationship between the person and the company, but it should be scoped by the time of the relationship. . This is simple to achieve by creating an abstract super-class called “EphermeralEntity”, making the shareholder relationship a subclass of this class along with the properties which point at the people involved in the relationships. . WOQL.add_class(&quot;EphemeralEntity&quot;) .label(&quot;Ephemeral Entity&quot;).abstract(true) .property(&quot;from&quot;, &quot;xsd:dateTime&quot;) .label(&quot;From&quot;) .property(&quot;to&quot;, &quot;xsd:dateTime&quot;) .label(&quot;To&quot;) WOQL.add_class(&quot;Shareholding&quot;).parent(&quot;EphemeralEntity&quot;) . In TerminusDB there is no fundamental distiction between things and relationships - relationships are things that can be interepreted as relationships by virtue of having properties that point at other things. . Boxing Datatypes . In RDF it is not possible to address triples with literal values directly. Therefore, if we want to add scopings or other annotations to a datatype property, we can’t do so directly. However, it is straightforward to create box classes to wrap the datatype properties in a simple object, with a regular naming convention. . Terminus WOQL contains some functions to support this situation. . boxClasses(prefix, classes, except, graph) loadXDDBoxes(parent, graph, prefix); this.loadXSDBoxes(parent, graph, prefix) . Open and Closed World Reasoning . Terminus supports both open and closed world reasoning. Schema graphs use closed world reasoning, but inference graphs use open world reasoning and allow the expression of inference rules. These rules are evaluated dynamically at query time rather than being materialised. . Inference Graph . The master terminus database makes use of an inference graph to describe the concept whereby authority should commute over resource inclusion (i.e. if I have authority for a thing, I have authority for the things that are included within that thing). . terminus:authority_scope owl:propertyChainAxiom ( terminus:authority_scope terminus:resource_includes ) . . Freestyle OWL . OWL is an almost infinitely flexible language. This document just provides a taste of the complex configurations that can be achieved by defining OWL schema and inference rules. TerminusDB supports a large subset of OWL in both inference and schema modes. The diagram below provies a snapshot of the OWL predicates that we currently support. It should be noted that all of OWL can be used in schemata and inference graphs, but only this subset will be correctly reasoned over. In some cases, the reason that we do not support a predicate is because, in practice, the way that the predicate is used does not correspond with it’s semantic definition (owl:SameAs) in other cases, it is because we have never had the need to use that specific formulation. It is normally possible to adequately capture a situation using a much smaller subset of the language. . . .",
    "url": "/docs/user-guide/schema/advanced/",
    "relUrl": "/user-guide/schema/advanced/"
  }
  ,"3": {
    "title": "API reference",
    "content": "API reference . Click on the button below for the documentation of: . JavaScript ClientPython Client .",
    "url": "/docs/api-reference/",
    "relUrl": "/api-reference/"
  }
  ,"4": {
    "title": "TerminusDB API",
    "content": "TerminusDB API . The TerminusDB Server includes a built in HTTP server which implements the Terminus API consisting of a number of endpoints which can be used to modify or query the system. . The terminus administration schema ( http://terminusdb.com/schema/terminus ) contains definitions for all of the data structures and properties used in the API. All arguments and returned messages are encoded as JSON. . . . Connect Example | Arguments | Return | | Create Database Example | Arguments | Return | | Delete Database Return | | Get Triples Example | Arguments: | Return | | Update Triples Example | Argument | Return | | Class Frame Example | Argument | Return | | WOQL Query Example | | Clone Arguments | Example | | Fetch Arguments | Example | | Rebase Arguments | | Push Arguments | Errors | | Branch Arguments | Example | | Create graph Arguments | | Delete graph Arguments | | . Connect . GET http://&lt;server&gt;/ . Connects to a TerminusDB Server and receives a Capability Document which defines the client’s permissions on the server. . Example . curl -X GET http://localhost:6363/ --user &#39;username:password&#39; . Arguments . The username and password for the client to connect to the server needs to be supplied as basic-auth. Depending if the server has been compiled with JWT support, the authentication can be a JWT token with the https://terminusdb.com/nickname key provided as the username. . Return . A document of type terminus:Capability (or one of its subclasses) http://terminusdb.com/schema/terminus#Capability . &quot;@context&quot;: { &quot;doc&quot;:&quot;http://localhost/terminus/document/&quot;, &quot;owl&quot;:&quot;http://www.w3.org/2002/07/owl#&quot;, &quot;rdf&quot;:&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;, &quot;rdfs&quot;:&quot;http://www.w3.org/2000/01/rdf-schema#&quot;, &quot;terminus&quot;: &quot;http://terminusdb.com/schema/terminus#&quot; }, &quot;@id&quot;:&quot;doc:admin&quot;, &quot;@type&quot;:&quot;terminus:User&quot;, &quot;rdfs:comment&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;This is the server super user account&quot;}, &quot;rdfs:label&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;Server Admin User&quot;}, &quot;terminus:authority&quot;: { &quot;@id&quot;:&quot;doc:access_all_areas&quot;, &quot;@type&quot;:&quot;terminus:ServerCapability&quot;, &quot;rdfs:comment&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;Access all server functions&quot;}, &quot;rdfs:label&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;All Capabilities&quot;}, &quot;terminus:action&quot;: [ {&quot;@id&quot;:&quot;terminus:class_frame&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:create_database&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:create_document&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:delete_database&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:delete_document&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:get_document&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:get_schema&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:update_document&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:update_schema&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:woql_select&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;}, {&quot;@id&quot;:&quot;terminus:woql_update&quot;, &quot;@type&quot;:&quot;terminus:DBAction&quot;} ], &quot;terminus:authority_scope&quot;: [ { &quot;@id&quot;:&quot;doc:dima&quot;, &quot;@type&quot;:&quot;terminus:Database&quot;, &quot;rdfs:comment&quot;: { &quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;This is a DB created for Dima to test the ontoogies&quot; }, &quot;rdfs:label&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;Dima Test DB&quot;}, &quot;terminus:allow_origin&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;*&quot;}, &quot;terminus:id&quot;: { &quot;@type&quot;:&quot;xsd:anyURI&quot;, &quot;@value&quot;:&quot;http://localhost/dima&quot; }, &quot;terminus:instance&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;document&quot;}, &quot;terminus:schema&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;schema&quot;} }, { &quot;@id&quot;:&quot;doc:documentation&quot;, &quot;@type&quot;:&quot;terminus:Database&quot;, &quot;rdfs:comment&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;This is the documentation db&quot;}, &quot;rdfs:label&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;Documentation database&quot;}, &quot;terminus:allow_origin&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;*&quot;}, &quot;terminus:id&quot;: { &quot;@type&quot;:&quot;xsd:anyURI&quot;, &quot;@value&quot;:&quot;http://localhost/documentation&quot; }, &quot;terminus:instance&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;document&quot;}, &quot;terminus:schema&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;schema&quot;} }, { &quot;@id&quot;:&quot;doc:terminus&quot;, &quot;@type&quot;:&quot;terminus:Database&quot;, &quot;rdfs:comment&quot;: { &quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;The master database contains the meta-data about databases, users and roles&quot; }, &quot;rdfs:label&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;Master Database&quot;}, &quot;terminus:allow_origin&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;*&quot;}, &quot;terminus:id&quot;: { &quot;@type&quot;:&quot;xsd:anyURI&quot;, &quot;@value&quot;:&quot;http://localhost/terminus&quot; } }, { &quot;@id&quot;:&quot;doc:server&quot;, &quot;@type&quot;:&quot;terminus:Server&quot;, &quot;rdfs:comment&quot;: { &quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;The current Database Server itself&quot; }, &quot;rdfs:label&quot;: {&quot;@language&quot;:&quot;en&quot;, &quot;@value&quot;:&quot;The DB server&quot;}, &quot;terminus:allow_origin&quot;: {&quot;@type&quot;:&quot;xsd:string&quot;, &quot;@value&quot;:&quot;*&quot;}, &quot;terminus:id&quot;: {&quot;@type&quot;:&quot;xsd:anyURI&quot;, &quot;@value&quot;:&quot;http://localhost&quot;}, &quot;terminus:resource_includes&quot;: [ {&quot;@id&quot;:&quot;doc:dima&quot;, &quot;@type&quot;:&quot;terminus:Database&quot;}, {&quot;@id&quot;:&quot;doc:documentation&quot;, &quot;@type&quot;:&quot;terminus:Database&quot;}, {&quot;@id&quot;:&quot;doc:terminus&quot;, &quot;@type&quot;:&quot;terminus:Database&quot;} ] } ] } } . Create Database . POST http://&lt;server&gt;/db/&lt;account&gt;/&lt;dbid&gt; . Create a new database ex nihilo. . Example . curl -X POST http://localhost:6363/db/dima/test --user &#39;username:password&#39; . Arguments . Post argument is a JSON document of the following form: . { &quot;prefixes&quot; : { &quot;doc&quot; : &quot;http://my_document_prefix/document/&quot;, &quot;scm&quot; : &quot;http://my_document_prefix/schema#&quot;} &quot;label&quot; : &quot;A Label&quot;, &quot;comment&quot; : &quot;A Comment&quot; } . The prefixes “doc” and “scm” are required for normal operation of the database. They help define the default location of new elements greated with idgen, hash etc. . Return . A terminus result message indicating either terminus:success or terminus:failure . { &quot;terminus:status&quot; : &quot;terminus:success&quot; } . Delete Database . DELETE http://&lt;server&gt;/db/&lt;account&gt;/&lt;dbid&gt; . Deletes an entire Database. . Sends a HTTP DELETE request to the URL of the Database on a Terminus Server . curl -X DELETE --user &#39;user:secret_key&#39; http://localhost:6363/dima/test . Return . A terminus result message indicating either terminus:success or terminus:failure . { &quot;terminus:status&quot; : &quot;terminus:success&quot; } . Get Triples . GET http://&lt;server&gt;/triples/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/branch/&lt;branchid&gt;/&lt;type&gt;/&lt;schema_graphid&gt;` GET http://&lt;server&gt;/triples/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/commit/&lt;refid&gt;/&lt;type&gt;/&lt;schema_graphid&gt; . Retrieves the database triples for a graph encoded as turtle. This can be used to dump graphs from the database for import to other databases. . Example . curl --user &#39;:secret_key&#39; http://localhost/dima/test/local/branch/master/instance/main . Arguments: . None . Return . The database schema encoded as a JSON string containing the contents of a turtle file . &quot;@prefix rdf: pre&gt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; . @prefix ... OWL schema serialised as turtle ... &quot; . Update Triples . POST http://&lt;server&gt;/triples/&lt;account&gt;/&lt;dbid&gt;/local/branch/&lt;branchid&gt;/&lt;type&gt;/&lt;schema_graphid&gt; . Updates the specified graph by posting a new turtle version. Updates are atomic - the entire graph is replaced by the updated version by producing the necessary delta automatically. . Example . curl --user &#39;user:secret_key&#39; -d &quot;@my-schema.ttl&quot; -X POST http://localhost:6363/triples/dima/test/local/branch/master/schema/main . Argument . An update document with the contents of the turtle held by the “turtle” key. . { &quot;turtle&quot;: &quot;@prefix rdf: ... OWL schema serialised as turtle ...&quot;, &quot;commit_info&quot;: { &quot;author&quot; : &quot;dima&quot;, &quot;message&quot; : &quot;Fixing frob class&quot; } } . Return . A terminus result message indicating either terminus:success or terminus:failure . {&quot;terminus:status&quot;:&quot;terminus:success&quot;} . Class Frame . GET http://&lt;server&gt;/frame/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/branch/&lt;branchid&gt; GET http://&lt;server&gt;/frame/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/commit/&lt;refid&gt; . Retrieves a frame representation of a class within the ontology - a json representation of all the logic contained in the class. . Example . curl -X GET --user &#39;admin:secret_key&#39; &quot;http://localhost:6363/dima/test/local/branch/master&quot; . Argument . The class that the frame is for must be passed in the terminus:class property . { &quot;class&quot; : &quot;http://terminusdb.com/schema/terminus#Agent&quot; } . Return . An array of frames, each of which is encoded as a JSON-LD frame document and each of which represents a single property in the class frame. . . WOQL Query . POST http://&lt;server&gt;/woql/ POST http://&lt;server&gt;/woql/terminus POST http://&lt;server&gt;/woql/&lt;account&gt;/&lt;dbid&gt; POST http://&lt;server&gt;/woql/&lt;account&gt;/&lt;dbid&gt;/_meta POST http://&lt;server&gt;/woql/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt; POST http://&lt;server&gt;/woql/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/_commit POST http://&lt;server&gt;/woql/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/branch/&lt;branchid&gt; POST http://&lt;server&gt;/woql/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/commit/&lt;refid&gt; . WOQL select allows users to perform queries from WOQL. The default query object is formed from the path. No path means no default query source. . The path following WOQL will set the default collection for the query. For instance, if you specify terminus, you will see information from the terminus core database (assuming that you have admin privileges). If you specify &lt;dbid&gt;/_meta you will see the graph which contains information about all repositories available for &lt;dbid&gt;. . For more information on collection descriptors, see: [Collection Descriptors]. . Example . curl -X POST --user &#39;admin:root&#39; &quot;http://localhost:6363/woql/terminus&quot; -d &#39;{ &quot;@type&quot; : &quot;Triple&quot;, &quot;subject&quot; : { &quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : { &quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Subject&quot;}}, &quot;predicate&quot; : { &quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : { &quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Predicate&quot;}}, &quot;object&quot; : { &quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : { &quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Object&quot;}}}&#39; -H &quot;Content-Type: application/json&quot; . Clone . POST http://&lt;server&gt;/clone/&lt;account&gt;/[&lt;new_dbid&gt;] . Allows you to clone a database which already exists into [&lt;new_dbid&gt;]. . Arguments . The payload provides the resource identifier of the repo / db that we want to clone. . If the new_dbid is provided, this id will be used locally to refer to the DB, otherwise whatever the cloned name is will be used. . { &quot;clone&quot;: &quot;http://hub.terminusdb.com/jimbob/special_sauces&quot; } . Example . curl -X POST --user &#39;admin:root&#39; &quot;http://localhost:6363/admin/into&quot; -d &#39;{ &quot;clone&quot; : &quot;http://hub.terminusdb.com/xlea/from&quot; }&#39; -H &quot;Content-Type: application/json&quot; . This clones the remote repository “from” on “terminusdb.com” into our local database “into”. . Fetch . POST http://terminus.db/fetch/&lt;account&gt;/&lt;dbid&gt;/&lt;repo_id&gt; . Fetches all new commits from a remote repository. This enables you to get current with a remote so that all changes since last fetch are now stored locally. . Arguments . The payload is the id of the last repository head commit. This is visible in the graph /&lt;account&gt;/&lt;dbid&gt;/_meta on the repository of interest under the repository:repository_head property. . Example . curl -X POST --user &#39;admin:root&#39; &quot;http://localhost:6363/admin/into&quot; -d &#39;{ &quot;clone&quot; : &quot;http://hub.terminusdb.com/xlea/from&quot; }&#39; -H &quot;Content-Type: application/json&quot; . Rebase . POST http://terminus.db/rebase/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/branch/&lt;branchid&gt; . Replays commits from another branch or ref on top of the branch identified in the URI. This allows you to merge changes originating from elsewhere. . Arguments . { &quot;from&quot;: &quot;db/repo/branch/other_branch&quot; } . The “from” resource can be a resource identifier of a ref or branch. . Push . POST http://terminus.db/push/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt; . Pushes commits and all deltas from a repository to the repository origin. This allows a remote to obtain all deltas which were created locally. . Arguments . None. . Errors . This errors when the remote has advanced. This can be resolve with “fetch”+”rebase” or “pull”. . Branch . POST http://terminus.db/branch/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/branch/&lt;new_branchid&gt; . Creates a new branch, enabling the user to split off from a current branch or ref to create a new updatable database which leaves the original unchanged. . Arguments . We send a resource identifier specifying the base of the new branch to be created. . { &quot;from&quot; : &quot;&lt;resource&gt;&quot; } . Example . curl -X POST --user &#39;admin:root&#39; &quot;http://localhost:6363/admin/into/local/branch/dev&quot; -d &#39;{ &quot;from&quot; : &quot;admin/into/local/branch/master&quot; }&#39; -H &quot;Content-Type: application/json&quot; . Create graph . POST http://terminus.db/graph/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/branch/&lt;branchid&gt;/&lt;instance|schema|inference&gt;/&lt;graphid&gt; . Creates a new graph in a given branch as either instance, schema or inference with the name “graphid”. . Arguments . This takes a post parameter: . {&quot;commit_info&quot; : { &quot;author&quot; : Author, &quot;message&quot; : Message }} . Delete graph . DELETE http://terminus.db/graph/&lt;account&gt;/&lt;dbid&gt;/&lt;repo&gt;/branch/&lt;branchid&gt;/&lt;instance|schema|inference&gt;/&lt;graphid&gt; . Deletes the already existing graph from a given branch as either instance, schema or inference with the name “graphid”. . Arguments . This takes a post parameter: . {&quot;commit_info&quot; : { &quot;author&quot; : &quot;Steinbeck&quot;, &quot;message&quot; : &quot;My Commit Message&quot; }} .",
    "url": "/docs/user-guide/api/",
    "relUrl": "/user-guide/api/"
  }
  ,"5": {
    "title": "Full Architecture",
    "content": "Full Architecture . . Architecture | . TerminusDB is architected as a revision controlled database from the ground up. In TerminusDB, revision control is based on a model quite similar to the one used in git. However, where git uses lines of code added or deleted, TerminusDB uses triples added or deleted. . picture of delta here . Each collection of additions and deletions is called a delta or delta layer. These deltas are then appended together in a chain (or tree) to form what is the current state of our graph. This approach of always giving the changed information as a delta makes TerminusDB an append only database. . When we query for data, we start at the top of the stack, and search downwards looking for triples added, which have not been deleted. . Each graph represents sets of triples. That is, a triple is either there, or it is not. There is no notion of it being in the graph multiple times. This simplifies our model of changes, merges and updates. . Architecture . . TerminusDB is structured as a hierarchy of graphs. Each level of the hierarchy is itself a graph which can be queried and which stores information about the graphs below it. . At the heighest level is the TerminusCore graph. This stores the records concerning all users and databases in the system. . For each database there is corresponding “_meta” graph which stores information about which repositories are present for a datbase. This includes at least the “local” repository. However it may also contain any number of remote repositories as well. These remotes represent other TerminuDB installations, and can be used to push or pull changes and collaborate with others. . Each of these repositories consists of a “_commit” graph which stores information about the branchs that we have, commit chains, and the graphs associated with each commit. . Finally commits point to the instance and schema graphs associated with a commit. This is important since schema and instance graphs have to move in lock-step to maintain consistency. . We will look more closely at the commit graph and then move on to the various operations which TerminusDB can perform. .",
    "url": "/docs/user-guide/revision-control/architecture/",
    "relUrl": "/user-guide/revision-control/architecture/"
  }
  ,"6": {
    "title": "Branching",
    "content": "Branching . . Coming Soon | . Coming Soon .",
    "url": "/docs/user-guide/revision-control/branching/",
    "relUrl": "/user-guide/revision-control/branching/"
  }
  ,"7": {
    "title": "From RDBMS databases to TerminusDB",
    "content": "From RDBMS databases to TerminusDB . . The Dataset | Query language | Create Schema | Load Data | Query the Data | . Most of your applications need to store data somewhere and probably relational databases like MySQL, PostgreSQL etc.. are the most commonly used for this purpose. . Passing from a relational database to TerminusDB requires some effort and a shift in your state of mind, but it can be done relatively fast. In this tutorial we’ll show you some parallels with how TerminusDB handles tasks compared to relational databases and the goals you can achieve with TerminusDB that are difficult to do with others databases. . if you have never used TerminusDB before, this article includes everything you need to get started with TerminusDB. My First TerminusDB Graph Visualisation — Bike Share Data. . Note: We are assuming you have knowledge of relational database concepts and you already know how to write a simple sql (Structured Query Language) statement. . . The Dataset . In our examples we use the collection of data about the bike journeys between stations in Washington D.C., USA. . . The CSV data used this tutorial is available at https://terminusdb.com/t/data/bike_tutorial.csv . . Query language . As you already know SQL is a standard language for accessing and manipulating relational databases. . In TerminusDB we use WOQL (Web Object Query Language). It is a unified model query language, WOQL’s primary syntax and interchange format is in JSON-LD. All our example are writing using woql.js a javascript layer that help you to compose WOQL query. . . Create Schema . A conceptual database schema is a description of a database structure, data types, and the constraints on the database. . We can consider a relational database as a collection, or a set of tables. For storing our dataset we need three tables: bikes, stations and journeys. Here the complete schema . Each table consists of rows and columns, in very simple way the columns specify the type of data, where the rows contain the actual data itself and the tables are related to each other. . Let’s see a fragment of schema: . CREATE TABLE `journeys` ( `idJourney` int(11) NOT NULL AUTO_INCREMENT, `bikeId` int(11) NOT NULL, ......), FOREIGN KEY (bikeId) REFERENCES bikes(idBike), . Here our logical relationship from tables: The bikeId column is a FOREIGN KEY to the table bikes (idBike column). . In terminusDB instead of tables we have documents, so for our dataset we need to create three different documents: Station, Journey and Bicycle, every document have a label and a description and is identified by an unique URL. In our documents we have properties to describe the type of data and the documents are related to each other as interlinked concepts. . An example of relationship between documents written in woql.js . WOQL.when(true).and( WOQL.doctype(&quot;Station&quot;) .label(&quot;Bike Station&quot;) .description(&quot;A station where bicycles are deposited&quot;), WOQL.doctype(&quot;Bicycle&quot;) .label(&quot;Bicycle&quot;), WOQL.doctype(&quot;Journey&quot;) .label(&quot;Journey&quot;) .property(&quot;journey_bicycle&quot;, &quot;Bicycle&quot;).label(&quot;Bicycle Used&quot;) .property(&quot;start_time&quot;, &quot;dateTime&quot;) .....) . In the Journey document the range data type of the journey_bicycle property (ObjectProperty) is the Bicycle document. . . Load Data . What we wish to do now is load the data from our .csv file inside our relational database, but which road map follows to save the integrity of the data relationship, you can use an external tool or you can implement your sql statement. . You could write an sql statement like this to import the csv file inside bikes or stations . LOAD DATA LOCAL INFILE &#39;bike_tutorial.csv&#39; INTO TABLE bikes FIELDS TERMINATED BY &#39;,&#39; LINES TERMINATED BY &#39; n&#39; IGNORE 1 LINES (@col1,@col2,@col3,@col4,@col5,@col6,@col7,@col8) set bikeNumber=@col8; . But populating the journeys table could be more complicated because you have to get bikeId and stationId from the preview table, maybe you can use a temporary table to load all the CSV data and after, you can move the data from the temporary table to bikes, stations, journeys. . In TerminusDB we have a very cleaner solution to import csv files into the database, with a data integrity check for any newly imported records. . TerminusDB is accessible in very easy with JavaScript using the woql.js layer A fragment of an import query. . const csv = WOQL.get( WOQL.as(&quot;Start station&quot;,&quot;v:Start_Station&quot;) .as(&quot;End station&quot;, &quot;v:End_Station&quot;) ...... .as(&quot;End station number&quot;, &quot;v:End_ID&quot;) .as(&quot;Bike number&quot;, &quot;v:Bike&quot;) .as(&quot;Member type&quot;, &quot;v:Member_Type&quot;) ).remote(&quot;https://terminusdb.com/t/data/bike_tutorial.csv&quot;) . We refer the first row of our file that contain the column headers in our variables, for example the field “Bike number” refers the variable “v:Bike” . //Clean data for insert const wrangles = [ WOQL.typecast(&quot;v:Duration&quot;, &quot;xsd:integer&quot;, &quot;v:Duration_Cast&quot;), WOQL.typecast(&quot;v:Bike&quot;, &quot;xsd:string&quot;, &quot;v:Bike_Label&quot;), WOQL.typecast(&quot;v:Start_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:ST_Cast&quot;), WOQL.typecast(&quot;v:End_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:ET_Cast&quot;), WOQL.typecast(&quot;v:Start_Station&quot;, &quot;xsd:string&quot;, &quot;v:SS_Label&quot;), WOQL.typecast(&quot;v:End_Station&quot;, &quot;xsd:string&quot;, &quot;v:ES_Label&quot;), WOQL.idgen(&quot;doc:Journey&quot;,[&quot;v:Start_ID&quot;,&quot;v:Start_Time&quot;,&quot;v:Bike&quot;],&quot;v:Journey_ID&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:Start_ID&quot;],&quot;v:Start_Station_URL&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:End_ID&quot;],&quot;v:End_Station_URL&quot;), WOQL.idgen(&quot;doc:Bicycle&quot;,[&quot;v:Bike_Label&quot;],&quot;v:Bike_URL&quot;), WOQL.concat(&quot;v:Start_ID - v:End_ID @ v:Start_Time&quot;,&quot;v:J_Label&quot;), WOQL.concat(&quot;Bike v:Bike from v:Start_Station to v:End_Station at v:Start_Time until v:End_Time&quot;,&quot;v:Journey_Description&quot;) ]; . We cast (WOQL.typecast(a,b,c) method) the variable “V:Bike” as string (“xsd:string”) and refer it in a new variable “V:Bike_Label” . We create an unique id (WOQL.idgen(a,b,c) to every document. Example for “doc:Bicycle” document we create an id from the “v:Bike_Label” and refer it in the “v:Bike_Url” . const inserts = WOQL.and( WOQL.insert(&quot;v:Journey_ID&quot;, &quot;Journey&quot;).label(&quot;v:J_Label&quot;) .description(&quot;v:Journey_Description&quot;) ..... .property(&quot;journey_bicycle&quot;, &quot;v:Bike_URL&quot;), ..... WOQL.insert(&quot;v:Bike_URL&quot;, &quot;Bicycle&quot;) .label(&quot;v:Bike_Label&quot;) ); . Now we can insert the data inside our database. We create a “Bicycle” document for every “v:Bike_URL” value and we link this value inside the “journey_bicycle” property in Journey document. Our relationship link between document has been created ❗ In this article the complete example My First TerminusDB Graph Visualisation — Bike Share Data. . . Query the Data . Now, how we write our query for getting all the information about the bike journeys. . Here an Sql example . SELECT journeys.startTime, journeys.endTime, bikes.bikeNumber, journeys.memberType, journeys.duration, startStation.address as startStation, startStation.stationNumber as startStationNumber, endStation.address as endStation, endStation.stationNumber as endStationNumber FROM journeys INNER JOIN stations as startStation ON journeys.startStation = startStation.idStation INNER JOIN stations as endStation ON journeys.endStation = endStation.idStation INNER JOIN bikes ON journeys.bikeId=bikes.idbike; . Let’s see the TerminusDB woql query . WOQL.select(&quot;v:Bike_Number&quot;, &quot;v:End_Time&quot;, &quot;v:Start_Time&quot;,&quot;v:Start_Label&quot;, &quot;v:End_Label&quot;,&quot;v:Duration&quot;).and( WOQL.triple(&quot;v:Journey&quot;, &quot;type&quot;, &quot;scm:Journey&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;duration&quot;, &quot;v:Duration&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;end_time&quot;, &quot;v:End_Time&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;start_time&quot;, &quot;v:Start_Time&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;start_station&quot;, &quot;v:Start&quot;), WOQL.opt().triple(&quot;v:Start&quot;, &quot;label&quot;, &quot;v:Start_Label&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;end_station&quot;, &quot;v:End&quot;), WOQL.opt().triple(&quot;v:End&quot;, &quot;label&quot;, &quot;v:End_Label&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;journey_bicycle&quot;, &quot;v:Bike&quot;), WOQL.opt().triple(&quot;v:Bike&quot;, &quot;label&quot;, &quot;v:Bike_Number&quot;) ) . Could you guess that the TerminusDB schema model is an ontology (OWL) ? It is extremely difficult to express queries against graph structured ontology, but with our query language we are shielded from the complexity of interfacing with the ontology keeping the power of an ontology data model. ❗ You can not query an ontology with sql. . Let’s keep to practise ❗ .",
    "url": "/docs/getting-started/comparison/child/",
    "relUrl": "/getting-started/comparison/child/"
  }
  ,"8": {
    "title": "Chooser View",
    "content": "Chooser View . This section covers all of the rules which can be applied to a chooser view. As mentioned in previous section a chooser view can be defined as shown below: . view = View.chooser() . All other rules are accessible as chaining functions of variable view. . 1) show_empty . Takes a string as argument and displays this as placeholder on load of chooser when nothing hasm been chosen yet. . view.chooser().show_empty(&quot;Select Something&quot;) . 2) sort . Allows to select a result and sort it in any direction. . view.sort(&#39;c&#39;) . 3) direction . Specifies the direction in which chooser value needs to be sorted (asc or desc) . view.sort(&#39;c&#39;).direction(&#39;asc&#39;) . 4) values . Displays the values of chooser of whatever you want to display . view.values(&#39;v:Names&#39;) // displays the values of v:Name . 5) labels . Displays labels of results as values in drop down of chooser . view.labels(&quot;v:Label&quot;) . 6) changeSize . Allows to change table page size . view.changeSize(true) . 7) pager . on set to true allows pagination . view.pager(true) . 8) pagesize . Defines minimum page size of a table . view.pagesize(10) // displays only 10 rows per page .",
    "url": "/docs/user-guide/visualisation/chooser/",
    "relUrl": "/user-guide/visualisation/chooser/"
  }
  ,"9": {
    "title": "Classes",
    "content": "Classes in the TerminusDB Schema . . Introduction | Class Definitions Class ID | Label / Name | Description | Parent Classes | Abstract Tag | | Class Definition Examples WOQL.js | WOQL.py | OWL | | Document Classes WOQL.js | WOQL.py | OWL | | Class Properties | . Tell me what type of a thing it is and I will know what to do with it . . Introduction . In the TerminusDB schema, classes are used to define the shapes of the data structures that we store in the database. Every fragment of data saved in the database is associated with a particular type and this type is defined by it’s class definition in the schema. So, if, for example, we wanted to save data structures of type Customer, we would first define the Customer class in the schema. . Classes are relatively simple structures - but they can be combined in a variety of ways to produce complex results. . . Class Definitions . A class definition is made up of a small number of properties in the Terminus schema: . Class ID | Label / Name | Description | Parent Classes | Abstract Tag | Class ID . Under the hood TerminusDB uses OWL and RDF for defining Schemas. In RDF, all ids are IRIs and this is the case with class IDs, like all IDs in TerminusDB. However, rather than using full URLs, it’s much more convenient to express things in a compressed form, with prefixes that map to an IRI base providing namespace safety, with fragment ids which identify the particular class. So for example, rather than writing . http://terminusdb.com/john/crm#Person it’s much more convenient to write: crm:Person - and define the crm prefix to map to the actual URL. . In TerminusDB, a predefined prefix is part of every database - the scm namespace is local to every database and allows you to create a class that is local to that database, with a valid IRI which will not clash with any other namespaces. In general, unless you know what you are doing, you should always just use the scm: prefix for all your classes. You can use whatever URLs you like for your classes but this makes it more difficult to work with prefixed forms - you have to define all the prefixes you want to use explicitly and have to remember what belongs where. . In TerminusDB we follow the usual naming conventions for OWL - class names start with a capital and multiple words are CamelCased together. URL prefixes for classes end with the URL fragment separator ‘#’ . In most cases, in TerminusDB you won’t need to specify the class prefix - if you are using the default scm: prefix, it will be automatically added when no prefix is supplied. You just need to choose an id for your class that is meaningful, if possible according to the capitalisation conventions above. Because the class ID forms part of an IRI, you cannot use spaces in class names, other special characters are permitted but should be used with extreme caution. . Finally, note that the class URL does not have to dereference to anything at the chosen URL. From the point of view of the database, it is just a unique identifier for the class, nevertheless, it is best practice to only use URLs that will actually dereference properly. If at all possible, if you are making your URLs publically availalble, you should try to only use URLs that dereference to a representation of the class. . Label / Name . In addition to having an id, each class can have one or more textual names associated with it. Internally, these use the rdfs:label predicate from OWL. These labels are useful in generating user interfaces and tables, etc, with human readable identifiers rather than IRIs. It is strongly recommended that every class have an associated label. . Description . Each class can have a description associated with it, using the rdfs:comment predicate. Like comments in code, textual descriptions of the intent of the designer who created a data structure are extremely valuable for those who must use and modify their systems. It is strongly recommended that every class have an associated description. . Parent Classes . Classes can be designated as subclasses of other classes using the rdfs:subClassOf predicate, according to the standard OWL semantics. Intuitively this is an inheritance mechanism for data structures, the definition of a subclass includes and extends the definition of its parent class. That is to say, that it gets all of the parent’s defined properties and can add its own new ones. Note that TerminusDB supports multiple inheritance - a class can have multiple parents, allowing the modelling of complex multi-dimensional . Abstract Tag . TerminusDB includes a mechanism for tagging a class as abstract - a common requirement in data modelling where we wish to create a parent class which groups together the definition of various shared features but never actually exists in practice. For example, we might have a class called Agent representing people and automated processess. We can tag this as terminus:abstract to indicate that, it is such a class. . Class Definition Examples . There are two ways in which we can define classes in TerminusDB - directly in OWL, or through one of the WOQL coding language libraries like WOQL.js or WOQL.py. Generally we find that it is easier and quicker to use WOQL. Below we show parallel examples of class definitions in OWL, WOQL.js and WOQL.py . WOQL.js . WOQL.add_class(&quot;MyClass&quot;) .label(&quot;Class Name&quot;) .description(&quot;Class Description&quot;) .parent(&quot;MyOtherClass&quot;) .abstract(true) . WOQL.py . WOQLQuery().add_class(&quot;MyClass&quot;) .label(&quot;Class Name&quot;) .description(&quot;Class Description&quot;) .parent(&quot;MyOtherClass&quot;) .abstract(True) . OWL . scm:MyClass a owl:Class; rdfs:label &quot;Class Name&quot;@en; rdfs:comment &quot;Class Description&quot;@en; terminus:tag terminus:abstract; rdfs:subClassOf scm:MyOtherClass. . Document Classes . TerminusDB allows you to access data within it as documents as well as graphs. To take advantage of this feature, you need to tell the Database which classes should be treated as documents - classes that are not documents can be contained within documents, allowing you to build out documents with complex internal structure. TerminusDB provides the special terminus:Document class - all subclasses of this class are considered to be document classes. The below examples show how you define a document class in OWL, WOQL.js and WOQL.py . We provide a shortcut function doctype in WOQL.js and WOQL.py to allow easy definition of document classes. . WOQL.doctype(&quot;X&quot;)` is equivalent to `WOQL.add_class(&quot;X&quot;).parent(&quot;Document&quot;) . WOQL.js . WOQL.doctype(&quot;MyClass&quot;) .label(&quot;Class Name&quot;) .description(&quot;Class Description&quot;) . WOQL.py . WOQLQuery().doctype(&quot;MyClass&quot;) .label(&quot;Class Name&quot;) .description(&quot;Class Description&quot;) . OWL . scm:MyClass a owl:Class; rdfs:label &quot;Class Name&quot;@en; rdfs:comment &quot;Class Description&quot;@en; rdfs:subClassOf terminus:Document. . Class Properties . Properties are associated with properties via the rdfs:range and rdfs:domain predicates within property definitions. Intuitively, we can imagine that each class ‘owns’ the properties that it is the domain of (the left hand side of the property relationship) and these properties have ranges that represent the type of the value of that property (the right hand side of the triple). Property definitions are covered in the next section. .",
    "url": "/docs/user-guide/schema/classes/",
    "relUrl": "/user-guide/schema/classes/"
  }
  ,"10": {
    "title": "Cloning Databases",
    "content": "Cloning Databases . . Coming Soon | . Coming Soon .",
    "url": "/docs/user-guide/revision-control/cloning/",
    "relUrl": "/user-guide/revision-control/cloning/"
  }
  ,"11": {
    "title": "The Commit Graph",
    "content": "The Commit Graph . . Introduction Commit Chains - the basic data structure | | Diagram Explanation | Revision Control Queries Setting Head of WOQL client: Forming Resource String Manually | | Other Contents of Commit Graph - Database Level Meta-data Notes | | | . Introduction . In TerminusDB, every operation that updates the state of a database generates a Commit Record which allows us to recreate the state of the database exactly as it was at the time that the update was completed. Commit records and their associated metadata (timestamps, comments and designation of authorship) can be accessed through a special internal graph called the commit graph within each database. Just like everything else in TerminusDB, this commit data is exposed as a graph which can be queried just like any other graph. . There are three things that make the commit graph special and different from normal TerminusDB graphs: . In normal usage it is immutable and append only and never written directly to by the user, but only by the internal database engine (*) | Unlike normal data and schema graphs, it is not itself versioned | It has a very simple, pre-defined schema consisting of two principle object types (Branch &amp; Commit) and 5 main properties (timestamp, parent, author, message, head) | TerminusDB provides a simple query library, covered in the following sections, which provides simple-pre-rolled queries which will extract all of the important information from the commit graph needed to support revision control operations for you, and a simple time-slider UI in the console which does all the work for you, so in the vast majority of use-cases, you will never have to look inside the graph yourself or worry about its structure. . Still, while it is not absolutely necessary to understand the structure of the commit graph to use the various revision control operations, it can be helpful to have a mental model, and being able to query the graph itself directly really helps understanding what actually happened in these operations. This section provides full details of the data structures and queries that are used in the commit graph with enough detail that you should be able to construct your own custom revision control queries from scratch. . Commit Chains - the basic data structure . Diagram Explanation . . As can be seen in the figure above, the commit graph consists of some number of branches, in this case “master” and “dev”, which have a “head”, that is, a current commit which they are looking at. . Each commit in the graph (here labelled “a”, “b”, “c”, “d”, “e”, “f”, “i”, “j”) have some number of edges labelled “instance”, “schema”, or “inference”. This specifies which graphs are associated with a given commit. In term, these graphs have a name, and an ID which associates them with a unique database state (stored in the TerminusDB Layer Store). . In addition each commit points at a parent commit if it has one. This represents the previous state of the database, and allows us to time travel, or branch from other points in history. . . Revision Control Queries . Translating results from commit graph queries into actual revision control operations is very simple and almost always follows the same basic pattern. . We query the commit graph with some pattern, involving time, commit author or commit message, to find the id of the specific commit (or branch) we are interested in | We take the Commit ID from this result and use it to parameterise subsequent calls to the database and the database behaves as if its contents were exactly as they were at the time that the commit in question completed. | The following sections contain many practical examples of querying the commit graph to perform revision control operations. Below we present the general pattern that all such operations take and the two principle ways in which we can plug commit ids into revision control operations. The names of function and the basic paradigm is closely based on the operations and paradigms supported by git, the revision control system for code. . Setting Head of WOQL client: . The WOQL client libraries are designed in such a way that we they have an internal concept of a cursor or “head” which could be any branch or commit in the database. By setting the client head to a specific commit id or to a specific branch, we specify that all subsequent accesses to the Database API will be against that specific branch or historical state of the database rather than whatever the default (latest) version is. . Set “head” to a specific comit ID . CommitID = dbClient.query(Commit_Graph_Query) dbClient.ref(CommitID) . or . Branch = dbClient.query(Commit_Graph_Query) dbClient.checkout(Branch) . This sets the client’s internal head state. All subsequent access will not be done from the commit associated with the commit id or the branch head. . Once we have set the client’s head to point at a particular branch or commit, then subsequent api calls with that client will use that state in the following way: . client.branch(new_branch_id) | Creates a new branch with id new_branch_id starting from the client head (branch or commit id that we set in ref/checkout above). This allows us to start a new branch from any point in the commit history. . client.merge(target_branch) | Merge starting from the client head (branch or commit id that we set in ref/checkout above) into the branch called target_branch. This allows us to merge differences between any commit in our history and any branch (note we can only ever write into the head of a branch because old commits are immutable) . Forming Resource String Manually . WOQL.using(&quot;_commits&quot;) . It should be noted that internally in TerminusDB, a commit ID refers to a very complex structure which actually contains all of the relevant historical data, if you are interested in the internal data structures, they are fully documented in the Full Architecture section and associated papers. However from a user point of view, all you have to know is Commit IDs allow you to set the state of the database to exactly the state that it was when the related update completed and queries to the commit graph allow you to find the Commit IDs that you are interested in. . Other Contents of Commit Graph - Database Level Meta-data . prefixes | graph structure | . Prefixes are also stored at the level of the commit graph. The reason for this is that it is useful to set prefixes which can be shared by collaborators. The commit graph is the graph which is transported when we do push/pull/clone and other collaboration operations so all data intended to be shared needs to be in the commit graph. . Notes . Administrators can choose to active the write_to_commit_graph capability which will allow them to manually rewrite the commit graph, however, direct updates of the commit graph are completely unsupported and highly inadvisable as the chance of breaking the internal delicate datastructures that lie beneath is extremely high. If you choose to do so, proceed with caution and assume that you will destroy everything. | .",
    "url": "/docs/user-guide/revision-control/commit-graph/",
    "relUrl": "/user-guide/revision-control/commit-graph/"
  }
  ,"12": {
    "title": "Comparison with other tools",
    "content": "Comparison with other tools . There are a number of popular databases systems available in the market. This tutorial looks at the main differences between TerminusDB and Relational databases. .",
    "url": "/docs/getting-started/comparison",
    "relUrl": "/getting-started/comparison"
  }
  ,"13": {
    "title": "TerminusDB Console",
    "content": "Deep Dive into how to use the Console . . Home | New Database | Schema | Query | . The terminus console is a simple javascript client application which provides users with a User Interface for managing and querying TerminusDB. The console is implemented using React Javascript which takes the help of Terminus Client as a gateway for API calls and other libraries which talks to the Terminus Server. . . You can load the console in the browser - http://localhost:6363 Note - You will have to login in order to use the Hub services. The documentation in this section is restricted to console services. . Home . The Home Page, will be the landing page on loading the above URL which displays a list of all Database to which you have access. User is able to choose any Database from the list which will display more Database centric actions. . On download of the console, User will always be able to view the local Terminus DB installed in their local machine. The local database comes with the name terminus and holds information related to all other database and associated strings. Consider this terminus db as the master to which all other database are tied to. User can always look at a database document in this master database. . New Database . The New Database page allows user to create a new Database and manage them, more of this will be covered in link text . Schema . The Schema page shows off the database schema and provides tools to view and update the schema. . Query . The Query page allows you to query the database and view results. A set of saved queries are available to load and fire. .",
    "url": "/docs/user-guide/console",
    "relUrl": "/user-guide/console"
  }
  ,"14": {
    "title": "Create TerminusDB Graph with Console",
    "content": "Create TerminusDB Graph with Console . In here you will see a step-by-step guide to create your first knowledge with Terminus DB with TerminusDB console using WOQLjs. . . Create a database | Create a Schema | Load in the Data | Query The Data | Graph Visualisation | . Create a database . Open up the Terminus DB console ( default: http://localhost:6363/console ). Click on Create Database to start with. . . Click the Create Local Database . . You have to specify an id for the database, to make it memorable, let’s make it 1stdb (note that Terminus’ IDs are URLs and they cannot have spaces). As a title, enter the name you want to give your Database, something meaningful like My First Database. Then you can add a short description to your database, like It is my first database using TerminusDB 2.0. . . Click the Create New Database button at the top right, and you’ll automatically go to the main database page. Something like this: . . . Create a Schema . The schema allows you to organise data into meaningful objects, and it ensures data integrity — nothing goes into your database that is not in the schema. This is a TerminusDB super power — and ensures you derive long term value from your data. . The TerminusDB Console provides a schema editor using WOQL.js. Remaining on the query page, copy this WOQL.js query into the text box (remember to delete the previous query before entering this one): . WOQL.and( WOQL.doctype(&quot;Station&quot;) .label(&quot;Bike Station&quot;) .description(&quot;A station where bicycles are deposited&quot;), WOQL.doctype(&quot;Bicycle&quot;) .label(&quot;Bicycle&quot;), WOQL.doctype(&quot;Journey&quot;) .label(&quot;Journey&quot;) .property(&quot;start_station&quot;, &quot;Station&quot;) .label(&quot;Start Station&quot;) .property(&quot;end_station&quot;, &quot;Station&quot;) .label(&quot;End Station&quot;) .property(&quot;duration&quot;, &quot;integer&quot;) .label(&quot;Journey Duration&quot;) .property(&quot;start_time&quot;, &quot;dateTime&quot;) .label(&quot;Time Started&quot;) .property(&quot;end_time&quot;, &quot;dateTime&quot;) .label(&quot;Time Ended&quot;) .property(&quot;journey_bicycle&quot;, &quot;Bicycle&quot;) .label(&quot;Bicycle Used&quot;) ) . add a commit message in the box below (e.g. “creating schema”) and click Run Query . Let’s stop to review this schema-building WOQL query: . We perform all operations within the and. . So here’s the operations we have performed: . We created three different document types (given by the doctype function): Station , Journey and Bicycle | We added label (names) or description (short descriptions) to them. | We created properties for Journey, we do that by using the property function after Journey with the first argument as the name of the property and the second argument as the type (or range) of the property. | For each property, you have to provide an id and the type of that property in property, as with class you can add a label to it as well. | . Load in the Data . Now load the data from the CSV. We’re going to progressively extend the query to import the data, cleaning it and matching it as we go. WOQL is a highly composable language, you can combine queries arbitrarily using logical ANDs and ORs. . Let’s build the next query in steps and only hit Run Query at the end of the query (full query is available at the bottom of the section) . Go back to the Query page, and copy in the following query: . //Read data from CSV const csv = WOQL.get( WOQL.as(&quot;Start station&quot;,&quot;v:Start_Station&quot;) .as(&quot;End station&quot;, &quot;v:End_Station&quot;) .as(&quot;Start date&quot;, &quot;v:Start_Time&quot;) .as(&quot;End date&quot;, &quot;v:End_Time&quot;) .as(&quot;Duration&quot;, &quot;v:Duration&quot;) .as(&quot;Start station number&quot;, &quot;v:Start_ID&quot;) .as(&quot;End station number&quot;, &quot;v:End_ID&quot;) .as(&quot;Bike number&quot;, &quot;v:Bike&quot;) .as(&quot;Member type&quot;, &quot;v:Member_Type&quot;) ).remote(&quot;https://terminusdb.com/t/data/bike_tutorial.csv&quot;) //Transform data into correct shape for insert const wrangles = [ WOQL.typecast(&quot;v:Duration&quot;, &quot;xsd:integer&quot;, &quot;v:Duration_Cast&quot;), WOQL.typecast(&quot;v:Bike&quot;, &quot;xsd:string&quot;, &quot;v:Bike_Label&quot;), WOQL.typecast(&quot;v:Start_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:ST_Cast&quot;), WOQL.typecast(&quot;v:End_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:ET_Cast&quot;), WOQL.typecast(&quot;v:Start_Station&quot;, &quot;xsd:string&quot;, &quot;v:SS_Label&quot;), WOQL.typecast(&quot;v:End_Station&quot;, &quot;xsd:string&quot;, &quot;v:ES_Label&quot;), WOQL.idgen(&quot;doc:Journey&quot;,[&quot;v:Start_ID&quot;,&quot;v:Start_Time&quot;,&quot;v:Bike&quot;],&quot;v:Journey_ID&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:Start_ID&quot;],&quot;v:Start_Station_URL&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:End_ID&quot;],&quot;v:End_Station_URL&quot;), WOQL.idgen(&quot;doc:Bicycle&quot;,[&quot;v:Bike_Label&quot;],&quot;v:Bike_URL&quot;), WOQL.concat(&quot;v:Start_ID - v:End_ID @ v:Start_Time&quot;,&quot;v:J_Label&quot;), WOQL.concat(&quot;Bike v:Bike from v:Start_Station to v:End_Station at v:Start_Time until v:End_Time&quot;,&quot;v:Journey_Description&quot;) ]; //Combine with logical and WOQL.and(csv, ...wrangles) . If we hit Run Query for this section and you should see the following in the Results Viewer tab: . . Click on the table drop down menu in the top left of the results and switch to graph view: . . Now you can see your results in graph form. . We’ll explain each of the steps in this query in turn. As a first step, we saved the part of the query that imports the data from CSV in a const variable named csv. Then we create a list of WOQL operators and save it in another constvariable called wrangles, we combine the two parts of the query with a WOQL.and operator. . The wrangles clause uses 3 WOQL functions to transform the data into the correct form for input. In each case, the function creates a new variable as output — the last argument in each case. The idgen function generates IDs for our three document types Journey, Station, and Bicycle. The first argument is the prefix that will be used, the second is a list of variables which combine to give a unique identity for the id. For example, in Journey we use 3 fields in the csv (Start_ID, Start_Time and Bike) to generate a unique id Journey_ID. . Besides generating IDs, we also create new fields with new data types, for example, we use typecast to cast Duration into integer and store it as Duration_Cast. We can also use concat to contract new text formatted with variables in the fields — for example, to create Journey_Label. . We’ll insert them in the graph by adding triples! Triples are the atomic data entity in the RDF data model. We add the following to the query: . const inputs = WOQL.and(csv, ...wrangles) const inserts = WOQL.and( WOQL.insert(&quot;v:Journey_ID&quot;, &quot;Journey&quot;) .label(&quot;v:J_Label&quot;) .description(&quot;v:Journey_Description&quot;) .property(&quot;start_time&quot;, &quot;v:ST_Cast&quot;) .property(&quot;end_time&quot;, &quot;v:ET_Cast&quot;) .property(&quot;duration&quot;, &quot;v:Duration_Cast&quot;) .property(&quot;start_station&quot;, &quot;v:Start_Station_URL&quot;) .property(&quot;end_station&quot;, &quot;v:End_Station_URL&quot;) .property(&quot;journey_bicycle&quot;, &quot;v:Bike_URL&quot;), WOQL.insert(&quot;v:Start_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:SS_Label&quot;), WOQL.insert(&quot;v:End_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:ES_Label&quot;), WOQL.insert(&quot;v:Bike_URL&quot;, &quot;Bicycle&quot;) .label(&quot;v:Bike_Label&quot;) ); . This is the clause that actually inserts the data into the structure that we defined on our schema. . The insert function inserts a new node into the database with the id Journey_ID and type Journey we add properties like start_time, end_time, duration, start_station, end_station and label and put the variables produced above in their correct spots. | For Start_Station_URL, End_Station_URL and Bike_URL, we assign a type and label for each of them. | . Finally, we have to put all of the above together and create the query that reads the data from the csv, do the data wrangling and add them in the graph as triples. We add this to complete the query: . WOQL.and(inputs, inserts); . write some commit message again (e.g. “inserting data”) and click Run Query. Remember, this is getting the data in to our graph so you won’t have a query output just yet. It should look something like this: . . The full query in all it’s glory and in easy to copy format: . const csv = WOQL.get( WOQL.as(&quot;Start station&quot;,&quot;v:Start_Station&quot;) .as(&quot;End station&quot;, &quot;v:End_Station&quot;) .as(&quot;Start date&quot;, &quot;v:Start_Time&quot;) .as(&quot;End date&quot;, &quot;v:End_Time&quot;) .as(&quot;Duration&quot;, &quot;v:Duration&quot;) .as(&quot;Start station number&quot;, &quot;v:Start_ID&quot;) .as(&quot;End station number&quot;, &quot;v:End_ID&quot;) .as(&quot;Bike number&quot;, &quot;v:Bike&quot;) .as(&quot;Member type&quot;, &quot;v:Member_Type&quot;) ).remote(&quot;https://terminusdb.com/t/data/bike_tutorial.csv&quot;) //Clean data for insert const wrangles = [ WOQL.typecast(&quot;v:Duration&quot;, &quot;xsd:integer&quot;, &quot;v:Duration_Cast&quot;), WOQL.typecast(&quot;v:Bike&quot;, &quot;xsd:string&quot;, &quot;v:Bike_Label&quot;), WOQL.typecast(&quot;v:Start_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:ST_Cast&quot;), WOQL.typecast(&quot;v:End_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:ET_Cast&quot;), WOQL.typecast(&quot;v:Start_Station&quot;, &quot;xsd:string&quot;, &quot;v:SS_Label&quot;), WOQL.typecast(&quot;v:End_Station&quot;, &quot;xsd:string&quot;, &quot;v:ES_Label&quot;), WOQL.idgen(&quot;doc:Journey&quot;,[&quot;v:Start_ID&quot;,&quot;v:Start_Time&quot;,&quot;v:Bike&quot;],&quot;v:Journey_ID&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:Start_ID&quot;],&quot;v:Start_Station_URL&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:End_ID&quot;],&quot;v:End_Station_URL&quot;), WOQL.idgen(&quot;doc:Bicycle&quot;,[&quot;v:Bike_Label&quot;],&quot;v:Bike_URL&quot;), WOQL.concat(&quot;v:Start_ID - v:End_ID @ v:Start_Time&quot;,&quot;v:J_Label&quot;), WOQL.concat(&quot;Bike v:Bike from v:Start_Station to v:End_Station at v:Start_Time until v:End_Time&quot;,&quot;v:Journey_Description&quot;) ]; //combine inputs const inputs = WOQL.and(csv, ...wrangles) //generate data to be inserted const inserts = WOQL.and( WOQL.insert(&quot;v:Journey_ID&quot;, &quot;Journey&quot;) .label(&quot;v:J_Label&quot;) .description(&quot;v:Journey_Description&quot;) .property(&quot;start_time&quot;, &quot;v:ST_Cast&quot;) .property(&quot;end_time&quot;, &quot;v:ET_Cast&quot;) .property(&quot;duration&quot;, &quot;v:Duration_Cast&quot;) .property(&quot;start_station&quot;, &quot;v:Start_Station_URL&quot;) .property(&quot;end_station&quot;, &quot;v:End_Station_URL&quot;) .property(&quot;journey_bicycle&quot;, &quot;v:Bike_URL&quot;), WOQL.insert(&quot;v:Start_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:SS_Label&quot;), WOQL.insert(&quot;v:End_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:ES_Label&quot;), WOQL.insert(&quot;v:Bike_URL&quot;, &quot;Bicycle&quot;) .label(&quot;v:Bike_Label&quot;) ); //Combine inputs and inserts with when clause WOQL.when(inputs, inserts); . don’t forget to put in the commit message, then click Run Query. . . Query The Data . Back to the query page — again input into the WOQL.js query builder: . WOQL.select(&quot;v:Start&quot;, &quot;v:Start_Label&quot;, &quot;v:End&quot;, &quot;v:End_Label&quot;).and( WOQL.triple(&quot;v:Journey&quot;, &quot;type&quot;, &quot;scm:Journey&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;start_station&quot;, &quot;v:Start&quot;), WOQL.opt().triple(&quot;v:Start&quot;, &quot;label&quot;, &quot;v:Start_Label&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;end_station&quot;, &quot;v:End&quot;), WOQL.opt().triple(&quot;v:End&quot;, &quot;label&quot;, &quot;v:End_Label&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;journey_bicycle&quot;, &quot;v:Bike&quot;) ) . click Run Query . You should see the query returning a table: . . Here we used select to filter out the variables (those starting with v:) that appear in our output. Then we used and to link all the conditions we want to include, as you can see there are lot’s of triples to be conditioned. The ones with opt() means that they are optional — it will be ignored if that data is missing (instead of returning an error — very handy). . The query can be translated as below: . select all the Journeys | and all the start_stations of all the Journeys (let’s call them Start) | and, if any, all the labels of the start_stations (let’s call them Start_Label) | and all the end_stations of all the Journeys (let’s call them End) | and, if any, all the labels of the end_stations (let’s call them End_Label) | and all the journey_bicycles of all the Journeys (let’s call them Bike) | . Graph Visualisation . We can click the table drop down menu in the top right and get a graph view of the results: . . You can experiment with the query to find different things in the data. .",
    "url": "/docs/getting-started/start-tutorials/console_js/",
    "relUrl": "/getting-started/start-tutorials/console_js/"
  }
  ,"15": {
    "title": "Database Home",
    "content": "Database Home . This Interface shows the home page of a chosen database which displays details related to the database. A selector is provided where the user can swap between branches of the database. On flicking through these branches the entire state of Database would change. A history Navigator is a time slider which allows user to navigate through time starting from the date of which the database was created till current time. On sliding through the history navigator the state of the database would change to the chosen date time. . Details . Shows details of Database and provides you with a table of recent updates . Manage . In Manage tab, User can also push changes made to the database to Hub. If there’s a conflict while merging the database a WOQL Query is automatically generated which fix . Collaborate . In Collaborate tab, Users are provided with options in which they can invite or add other Hub users to access the current Database. In Order to perform this action the User should be having Manage rights on the database. On having Manage rights User can also assign/ update different capabilities to users. .",
    "url": "/docs/user-guide/console/database-home/",
    "relUrl": "/user-guide/console/database-home/"
  }
  ,"16": {
    "title": "Datatypes",
    "content": "Datatypes - Literals and Enumerated Types . . Introduction Principle XSD Types Supported | | Enumerated Types | Example Datatype Schema | . Introduction . TermiusDB follows OWL in using the xsd datatypes for defining basic literal types like strings and numbers. Every datatype property must be defined as having a specfic datatype which defines the range of acceptable values for that property. . TerminusDB supports the full range of xsd datatypes and adds a number of our own extended datatypes which are particularly useful in practice and are typically omitted from datatype defintions. . In practice, many of the XSD datatypes are not particularly useful - focused on legacy features of XML. However, xsd provides a well-defined and extensible framework for datatype definitions. . Terminus DB also provides support for the definition of enumerated datatypes. . Principle XSD Types Supported . Internally Terminus supports more xsd datatypes but most of them are not useful in practice - this table just lists the useful ones . Datatype JSON LD Example Notes . xsd:anyURI | {@type : &quot;xsd:anyURI&quot;, @value: &quot;https://veryloose definition/of a/uri&quot;} | | . xsd:base64Binary | {@type : &quot;xsd:base64Binary&quot;, @value: &quot;aGVsbG8gd29ybGQ=&quot;} | | . xsd:boolean | {@type : &quot;xsd:boolean&quot;, @value: true} | | . xsd:byte | {@type : &quot;xsd:byte&quot;, @value: 123} | A number between -128 and 127 | . xsd:date | {@type : xsd:boolean, @value: &quot;2001-10-23&quot;} | YYYY-MM-DD format with optional timezone suffix | . xsd:dateTime | {@type : &quot;xsd:dateTime&quot;, @value: &quot;2001-10-23T23:12:11.1&quot;} | YYYY-MM-DDTHH:MM:SS.sss format with optional timezone suffix | . xsd:dateTimeStamp | {@type : &quot;xsd:dateTimeStamp&quot;, @value: &quot;2001-10-23T23:12:11.1-05:00&quot;} | Same YYYY-MM-DDTHH:MM:SS.sss format as xsd:dateTime but the timezone suffix is required (+-HH:MM or Z to indicate UTC) | . xsd:decimal | {@type : &quot;xsd:decimal&quot;, @value: 23.323} | | . xsd:double | {@type : &quot;xsd:double&quot;, @value: 23.323323323423423} | | . xsd:float | {@type : &quot;xsd:float&quot;, @value: 23.3233223} | | . xsd:gDay | {@type: &quot;xsd:gDay&quot;, @value: &quot;01&quot;} | Refers to a day that occurs once every month format is DD | . xsd:gMonth | {@type: &quot;xsd:gMonth&quot;, @value: &quot;--09&quot;} | Refers to a month that occurs once every year, format is --MM | . xsd:gMonthDay | {@type: &quot;xsd:gMonthDay&quot;, @value: &quot;--09-23&quot;} | Refers to a month and day that occurs once every year, format is --MM-DD | . xsd:gYear | {@type: &quot;xsd:gYear&quot;, @value: &quot;2011&quot;} | 4 digit year - can also be negative -1000 refers to 1000 BCE | . xsd:gYearMonth | {@type: &quot;xsd:gYearMonth&quot;, @value: &quot;2011-01&quot;} | A specific month in a specific hear - format is YYYY-MM | . xsd:int | {@type: &quot;xsd:int&quot;, @value: 2} | The value space of xsd:int is the set of common single-size integers (32 bits), the integers between -2147483648 and 2147483647. Its lexical space allows any number of insignificant leading zeros. | . xsd:integer | {@type: &quot;xsd:integer&quot;, @value: -2} | The value space of xsd:integer includes the set of all the signed integers, with no restriction on range. Its lexical space allows any number of insignificant leading zeros. | . xsd:language | {@type: &quot;xsd:language&quot;, @value: &quot;EN-IE&quot;} | Values of the xsd:language type conform to RFC 3066, Tags for the Identification of Languages. | . xsd:long | {@type: &quot;xsd:long&quot;, @value: 543245345} | Long integer - double-size integers (64 bits) — the integers between -9223372036854775808 and 9223372036854775807. Its lexical space allows any number of insignificant leading zeros. | . xsd:negativeInteger | {@type: &quot;xsd:negativeInteger&quot;, @value: -543245345} | Less than 0 | . xsd:nonNegativeInteger | {@type: &quot;xsd:nonNegativeInteger&quot;, @value: 0} | Greater than or equal to 0 | . xsd:nonPositiveInteger | {@type: &quot;xsd:nonPositiveInteger&quot;, @value: 0} | Less than or equal to 0 | . xsd:positiveInteger | {@type: &quot;xsd:positiveInteger&quot;, @value: 1} | Greater than zero | . xsd:short | {@type: &quot;xsd:short&quot;, @value: 1} | A short integer (16 bits) between -32768 and 32767 | . xsd:string | {@language: &quot;en&quot;, @type: &quot;xsd:string&quot;, @value: &quot;this is the string&quot;} | If strings have a language, we can omit the type | . xsd:time | {@type: &quot;xsd:time&quot;, @value: &quot;01:02:03.3223&quot;} | Format is HH:MM:SS.ssss with an optional timezone suffix | . xsd:unsignedByte | {@type: &quot;xsd:unsignedByte&quot;, @value: 1} | Can take values of 0 to 255 | . xsd:unsignedInt | {@type: &quot;xsd:unsignedInt&quot;, @value: 64000} | Can take any value between 0 and 4294967295 | . xsd:unsignedLong | {@type: &quot;xsd:unsignedLong&quot;, @value: 64000} | An integer between 0 and 18446744073709551615 | . xsd:unsignedShort | {@type: &quot;xsd:unsignedShort&quot;, @value: 64000} | An integer between 0 and 65535 | . . XDD Types Supported . . Datatype Example Notes . xdd:coordinate | {@type: &quot;xdd:coordinate&quot;, @value: &quot;[43.35353234,45.66645634]&quot;} | Represents a point coordinate on the earth&#39;s surface, identified by a latitude, longitude pair, separated by a comma and wrapped with square brackets | . xdd:coordinatePolyline | {@type: &quot;xdd:coordinatePolyline&quot;, @value: &quot;[[23.23423432,-42.423423535],[43.35353234,45.66645634]]&quot;} | Represents a line across the earth&#39;s surface. An array of xdd:coordinate values, separated by a comma and wrapped with square brackets - there must be at least 2 coordinate pairs in the line. | . xdd:coordinatePolygon | {@type: &quot;xdd:coordinatePolygon&quot;, @value: &quot;[[23.23423432,-42.423423535],[43.35353234,45.66645634],[-65.35353234,-2.66645634]]&quot;} | Represents a closed polygon on the earth&#39;s surface. An array of xdd:coordinate values, separated by a comma and wrapped with square brackets - there must be at least 3 coordinate pairs in the line and they should form a closed shape. | . xdd:integerRange | {@type: &quot;xdd:integerRange&quot;, @value: &quot;[23,30]&quot;} | An uncertain integer number, what is somewhere between the two ranges, expressed either as i) an uncertainty range - somewhere between a and b, separated by a comma and wrapped in square brackets, or ii) a simple integer | . xdd:decimalRange | {@type: &quot;xdd:decimalRange&quot;, @value: &quot;[23.323,-3.6754]&quot;} | A decimal value expressed as an uncertainty range - somewhere between a and b (or a simple decimal number) | . xdd:dateRange | {@type: &quot;xdd:dateRange&quot;, @value: &quot;[2001-01-02,2003-03-01]&quot;} | A date expressed as an uncertainty range - somewhere between date a and date b | . xdd:gYearRange | {@type: &quot;xdd:gYearRange&quot;, @value: &quot;[2001,2003]&quot;} | A year expressed as an uncertainty range - somewhere between year a and year b | . xdd:url | {@type: &quot;xdd:url&quot;, @value: &quot;http://my.url.com/hello_world.png&quot;} | A valid HTTP/HTTPS URL | . xdd:email | {@type: &quot;xdd:email&quot;, @value: &quot;obama@whitehouse.gov&quot;} | A valid Email Address according to rfc 5322 | . xdd:html | {@type: &quot;xdd:html&quot;, @value: &quot;&lt;p&gt;hello world&lt;/p&gt;&quot;} | A HTML encoded string | . xdd:json | {@type: &quot;xdd:json&quot;, @value: &quot;{hello: &quot;world &quot;}&quot;} | A JSON encoded string | . . Enumerated Types . It is often useful to have properties that can take on one or more of an enumerated set of values (e.g. we might want a property that has a value of either: absent, present, or unknown) rather than just using strings. These types In the TerminusDB schema you can define specific properties as having ranges that are enumerated types in the following way. . let choices = [ [&quot;scm:absent&quot;, &quot;Absent&quot;, &quot;The feature was absent in this historical context&quot;], [&quot;scm:present&quot;, &quot;Present&quot;, &quot;The feature was present in this historical context&quot;], [&quot;scm:unknown&quot;, &quot;Unknown&quot;, &quot;It is not known whether the feature was present or absent in the context&quot;] ] WOQL.schema().generateChoiceList(&quot;Presence&quot;, &quot;Presence&quot;, &quot;The epistemic state - is the feature present?&quot;, choices) . In OWL, this is encoded in the following way: . scm:Presence a owl:Class ; rdfs:comment &quot;The epistemic state - is the feature present?&quot;@en ; rdfs:label &quot;Presence&quot;@en ; owl:oneOf ( scm:unknown scm:absent scm:present ) . scm:absent a scm:Presence ; rdfs:comment &quot;The feature was absent in this historical context&quot;@en ; rdfs:label &quot;Absent&quot;@en . scm:present a scm:Presence ; rdfs:comment &quot;The feature was present in this historical context&quot;@en ; rdfs:label &quot;Present&quot;@en . scm:unknown a scm:Presence ; rdfs:comment &quot;It is not known whether the feature was present or absent in the context&quot;@en ; rdfs:label &quot;Unkown&quot;@en . . Once an enumerated type has been created in this way, we can use it as the range of any properties we want. . WOQL.add_property(&quot;wear&quot;, &quot;Presence&quot;).label(&quot;Signs of Wear&quot;).domain(&quot;Article&quot;) . scm:wear a owl:ObjectProperty; rdfs:label &quot;Signs of Wear&quot;@en; rdfs:domain scm:Article; rdfs:range scm:Presence. . Note that in OWL, properties that use enumerated datatypes are objectProperties, not datatype properties. Finally, note that there are a very large number of ways in which enumerated properties can be implemented in OWL. TerminusDB provides various shortcuts which use this particular encoding but does not put any limit on how you choose to encode such concepts in the schema. You are free to use another different encoding schema at your pleaure. . Example Datatype Schema . The terminusdb-schema repository contains a datatypes.owl.ttl file which includes a class that has a broad range of TerminusDB datatypes in use. If you load the file below into a TerminusDB schema, you should be able to see all the examples of datatypes in action. . @prefix rdfs: &amp;lt;http://www.w3.org/2000/01/rdf-schema#&amp;gt; . @prefix xsd: &amp;lt;http://www.w3.org/2001/XMLSchema#&amp;gt; . @prefix owl: &amp;lt;http://www.w3.org/2002/07/owl#&amp;gt; . @prefix tcs: &amp;lt;http://terminusdb.com/schema/tcs#&amp;gt; . @prefix xdd: &amp;lt;http://terminusdb.com/schema/xdd#&amp;gt; . @prefix datatypes: &amp;lt;http://terminusdb.com/schema/datatypes#&amp;gt; . datatypes:DatatypeHolder a owl:Class ; rdfs:subClassOf tcs:Entity; rdfs:comment &quot;An entity that contains an example of every atomic datatype (non-compound) supported by the DB&quot;@en; rdfs:label &quot;Datatype Examples&quot;@en . datatypes:link a owl:ObjectProperty; rdfs:label &quot;Document Link Type&quot;@en; rdfs:domain datatypes:DatatypeHolder; rdfs:range datatypes:DatatypeHolder. datatypes:coord rdfs:label &quot;xdd:coordinate&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:coordinate . datatypes:coordline rdfs:label &quot;xdd:coordinatePolyline&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:coordinatePolyline . datatypes:coordpoly rdfs:label &quot;xdd:coordinatePolygon&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:coordinatePolygon . datatypes:dateRange rdfs:label &quot;xdd:dateRange&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:dateRange . datatypes:gYearRange rdfs:label &quot;xdd:gYearRange&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:gYearRange . datatypes:integerRange rdfs:label &quot;xdd:integerRange&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:integerRange . datatypes:decimalRange rdfs:label &quot;xdd:decimalRange&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:decimalRange . datatypes:email rdfs:label &quot;xdd:email&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:email . datatypes:html rdfs:label &quot;xdd:html&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:html . datatypes:url rdfs:label &quot;xdd:url&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:url . datatypes:anySimpleType rdfs:label &quot;xsd:anySimpleType&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:anySimpleType . datatypes:boolean rdfs:label &quot;xsd:boolean&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:boolean . datatypes:decimal rdfs:label &quot;xsd:decimal&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:decimal . datatypes:double rdfs:label &quot;xsd:double&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:double . datatypes:float rdfs:label &quot;xsd:float&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:float . datatypes:time rdfs:label &quot;xsd:time&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:time . datatypes:date rdfs:label &quot;xsd:date&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:date . datatypes:dateTime rdfs:label &quot;xsd:dateTime&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:dateTime . datatypes:dateTimeStamp rdfs:label &quot;xsd:dateTimeStamp&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:dateTimeStamp . datatypes:gYear rdfs:label &quot;xsd:gYear&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:gYear . datatypes:gYearMonth rdfs:label &quot;xsd:gYearMonth&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:gYearMonth . datatypes:gMonth rdfs:label &quot;xsd:gMonth&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xsd:gMonth . datatypes:json rdfs:label &quot;xdd:JSON&quot;@en ; a owl:DatatypeProperty ; rdfs:domain datatypes:DatatypeHolder ; rdfs:range xdd:json. xdd:coordinate a rdfs:Datatype ; tcs:refines xsd:string ; rdfs:label &quot;Coordinate&quot;@en ; rdfs:comment &quot;A longitude / latitude pair making up a coordinate.&quot;@en . xdd:coordinatePolyline a rdfs:Datatype ; tcs:refines xsd:string ; rdfs:label &quot;Coordinate Polyline&quot;@en ; rdfs:comment &quot;A JSON list of coordinates.&quot;@en . xdd:coordinatePolygon a rdfs:Datatype ; rdfs:label &quot;Coordinate Polygon&quot;@en ; tcs:refines xdd:coordinatePolyline ; rdfs:comment &quot;A JSON list of coordinates forming a closed polygon.&quot;@en . xdd:range a rdfs:Datatype ; tcs:tag tcs:abstract ; rdfs:label &quot;Range&quot;@en ; rdfs:comment &quot;Abstract datatype representing a value that is within a range of values. Enables uncertainty to be encoded directly in the data&quot;@en . xdd:dateRange a rdfs:Datatype ; rdfs:label &quot;Date Range&quot;@en ; tcs:refines xdd:range ; rdfs:comment &quot;A date (YYYY-MM-DD) or an uncertain date range [YYYY-MM-DD1,YYYY-MM-DD2]. Enables uncertainty to be encoded directly in the data&quot;@en . xdd:gYearRange a rdfs:Datatype ; rdfs:label &quot;Year Range&quot;@en ; tcs:refines xdd:range ; rdfs:comment &quot;A year (e.g. 1999) or an uncertain range of years: (e.g. [1999,2001]). Enables uncertainty to be encoded directly in the data&quot;@en . xdd:integerRange a rdfs:Datatype ; tcs:refines xdd:range ; rdfs:label &quot;Integer Range&quot;@en ; rdfs:comment &quot;Either an integer (e.g. 30) or an uncertain range of integers [28,30]. Enables uncertainty to be encoded directly in the data&quot;@en. xdd:decimalRange a rdfs:Datatype ; rdfs:label &quot;Decimal Range&quot;@en ; tcs:refines xdd:range ; rdfs:comment &quot;Either a decimal value (e.g. 23.34) or an uncertain range of decimal values (e.g.[23.4, 4.143]. Enables uncertainty to be encoded directly in the data&quot;@en . xdd:email a rdfs:Datatype ; tcs:refines xsd:string ; rdfs:label &quot;Email&quot;@en ; rdfs:comment &quot;A valid email address&quot;@en . xdd:url a rdfs:Datatype ; tcs:refines xsd:string ; rdfs:label &quot;URL&quot;@en ; rdfs:comment &quot;A valid http(s) URL&quot;@en . xdd:html a rdfs:Datatype ; tcs:refines xsd:string ; rdfs:label &quot;HTML&quot;@en ; rdfs:comment &quot;A string with embedded HTML&quot;@en . xdd:json a rdfs:Datatype ; tcs:refines xsd:string ; rdfs:label &quot;JSON&quot;@en ; rdfs:comment &quot;A JSON encoded string&quot;@en . terminus:Document a owl:Class ; rdfs:label &quot;Document Class&quot;@en ; rdfs:comment &quot;A class used to designate the primary data objects managed by the system - relationships and entities&quot;@en . .",
    "url": "/docs/user-guide/schema/datatypes/",
    "relUrl": "/user-guide/schema/datatypes/"
  }
  ,"17": {
    "title": "Developer guide",
    "content": "Developer guide . TerminusDB is open-source and contributions are welcome. Source codes are available on GitHub. Please refer to the corresponding repo for issues and contributions. . Contributing to terminusdb-server . Please refer to CONTRIBUTION.md in terminusdb/terminusdb-server . Show me . Contributing to terminusdb-store . Please refer to CONTRIBUTION.md in terminusdb/terminusdb-store . Show me . Contributing to terminusdb-client . Please refer to Contributing.md in terminusdb/terminusdb-client . Show me . Contributing to terminusdb-client-python . Please refer to Contributing.md in terminusdb/terminusdb-server . Show me .",
    "url": "/docs/developer-guide/",
    "relUrl": "/developer-guide/"
  }
  ,"18": {
    "title": "Essential basic functionality",
    "content": "Essential basic functionality . Retrieve and query datasets others have created . There are many high-quality datasets out there already, and we host many of them on terminushub. You can easily clone these datasets or integrate them in datasets of your own. After downloading them, they’ll be available to you for offline use - forever. . Work on a dataset without risking data loss . It can be scary to modify data. Nobody wants to lose hours, maybe even days of work by pressing a wrong button, or entering a wrong command. With terminusdb, you don’t have to fear. Every modification you do is stored in a way that allows you to undo. No matter how badly you screw up, you can always go back to an earlier time when things were right. . Whenever you modify your data, you’ll be asked to provide a message saying what you did. These will be kept in a log which you can view. If you so choose, you can go back to any previous version. . Keep your data valid with schemas . Structured data tends to follow rules. For example, a person has exactly one age, not zero or five. Terminusdb can enforce such rules on your data, so that when you try to give a person more than one age, the system will tell you that’s wrong, and why it is wrong. . If you have experience with relational databases, this is a bit like database constraints. However, the language terminusdb uses for schemas, OWL (the Web Ontology Language), is much more powerful than what you could accomplish in such systems. OWL is an industry standard with decades of research behind it. In terminusdb it ensures your data never goes bad. . Travel through time . Sometimes you don’t want to query the latest version of your database, but an older one. For example, for auditing purposes it may be useful to be able to query your database as it was at the end of the month, rather than how it is now. TerminusDB lets you query any revision. . Use branches to work on modifications . You may want to work on modifications to your data without messing with your ‘master’ version. For example, you may need to enter a lot of data over multiple days, but only make that the master version when it has all been entered. For this purpose, you can create branches. . A branch will start out with a copy of your data, but after that, any changes made will only be visible from that branch. The original data won’t be modified. When you are satisfied with all your changes, you can merge these changes back into your master version. . Share your work with others . When you’ve contributed to a dataset, or when you’ve created a completely new data set, you may want to share this with other people. Just like you can query and retrieve data sets others have made, others can also query and retrieve your data sets, if you make them available. . You can host these data sets yourself, by setting up TerminusDB on a server of your own, or you can use TerminusHub and let us handle the hosting for you. In both cases, any time you have changes you wish to share with the world, you can simply push these from your local machine to the central server, where others can pick them up. . Collaborate on data . Many datasets aren’t the work of one individual. They are built through the efforts of many collaborators. With TerminusDB, several people can collaborate on the same dataset and integrate eachother’s changes. . You can integrate other people’s work by rebasing your work on top of theirs, or by merging the changes together. In both cases, TerminusDB will help you ensure that the combined result will still pass all your constraints, and provides you with strategies to fix any problems that arise. .",
    "url": "/docs/getting-started/essential-basic/",
    "relUrl": "/getting-started/essential-basic/"
  }
  ,"19": {
    "title": "Graph View",
    "content": "Graph View . This section covers all of the rules which can be applied to a graph view. As mentioned in previous section a graph view can be defined as shown below: . view = View.graph() . 1) Width . Allows you to set the width of graph component. The argument value is considered as pixels. . view.graph().width(100) . 2) Height . Allows you to set the height of graph component. The argument value is considered as pixels. . view.graph().width(100).height(50) . 3) show_force . Provides a Gravitational view over the graph component. If set to false the graoh would simply appear rather than the floating effect. . view.graph().width(100).show_force(true) . 4) source . Alters the graph’s view by treating the element mentioned in argument as the graph’s source . view.graph().source(&quot;v:A&quot;) . 5) color . You can set color for graph’s nodes in rgb format. . view.graph().node(&quot;v:A&quot;).color([233, 54, 65]) . 5) fontfamily . Helps you to load icon families. By default Font Awesome is used here. . view.graph().fontfamily(&#39;font&#39;) . 6) edges . Alters the direction of edges pointing, based on values provided as arguments . view.graph().edges([&quot;v:B&quot;,&quot;v:A&quot;]) .",
    "url": "/docs/user-guide/visualisation/graph/",
    "relUrl": "/user-guide/visualisation/graph/"
  }
  ,"20": {
    "title": "Graphs",
    "content": "Graphs . . Introduction - Triples, Quads and (Named) Graphs | TerminusDB - Graph Types Instance Data Graph | Schema Graph | Inference Graph | | Addressing Graphs in Queries Setting Graph Filters for Queries | Setting Graph Identifiers for Updates | | Creating and Deleting Graphs WOQL.js | | Special Internal Graphs Commits Graph | Repository Graph | | . Introduction - Triples, Quads and (Named) Graphs . In RDF everything is a subject - property - object triple. The major benefit of this formulation is that we can achieve a naturally interlinked graph just by virtue of some triples having the same object as the subjects of other triples, and vice versa. The major drawback is that we naturally interlink everything without discrimination. In practice, it is often useful to divide up an RDF triple-store into separate chunks that can be managed seperately, interpreted differently, and can be selectively integrated - or not - with the rest of the triples in the database. The concept of an order Graph being internally divided into multiple Graphs, often known as Named Graphs has been developed to address this problem. They are a very simple concept - they allow you to store triples in different buckets, each identified by a name. . When a triple-store uses named graphs to store data, we can think of it as consisting of quads instead of triples - ` subject - predicate - object - graph ` as each triple is associated with a specific graph. Thus, for example, if we wanted to query a specific graph, rather than the default one, we might write: WOQL.quad(&quot;v:Person&quot;, &quot;dob&quot;, today, &#39;instance/birthdays&#39;) to query a specific graph for data rather rather than the triple form: WOQL.triple(&quot;v:Person&quot;, &quot;dob&quot;, today). . TerminusDB places no limits on the number of named graphs that can be created within a datbase but adopts simple defaults that support the most common use cases without requiring users to understand the deep details of the internal graph structures. Most users will never have to worry about anything except the difference between the schema graph and the instance data graph. . TerminusDB - Graph Types . Internally, each TerminusDB database is divided into a number of different named graphs. While named graphs are in general just buckets in which we can store different types of data. In TerminusDB there are three different types of graph which define how the data within the graph will be interpreted . Instance Data Graph | Schema Graph | Inference Graph | By default, in the TerminusDB console, databases are created with a single instance graph instance/main and a single schema graph schema/main. However, there is nothing mandatory about this configuration - databases can have no instance graphs or no schema graphs or multiple of each and they can be given whatever identifiers are desired. . Instance Data Graph . The instance data graph is where ordinary data is stored as RDF triples. The default instance data graph is instance/main. Databases can be configured to have multiple instance graphs and updates and queries can be routed to any combination of these instance graphs. In the most common configuration, each database will have exactly one instance graph called main. . Schema Graph . Each database can have one or more schema graphs configured. The default schema graph is schema/main. Schema graphs are special, because any data written to an instance graph in the database must obey the rules defined in the schema graph(s) of the database. The schema is defined in OWL, interpreted in a closed world, unique name reasoning regime. In the most basic configuration, a database will have a single schema graph, defining the properties and classes used in that database. Adding extra schema graphs is most useful in supporting loaing of schemas as libraries for reuse. For example, we can load the xdd (extended datatypes library) in its own schema graph. . Inference Graph . TerminusDB databases can be configured to have one or more inference graphs. Inference graphs consist of a set of OWL statements which will be interepreted dynamically in an open world regime, to generate dynamic predicates. In most common configurations, there is no inference graph. The internal terminus administration database does have an inference graph consisting of a single predicate, which expresses resource inclusion. . Addressing Graphs in Queries . In TerminusDB all graphs within a database can be addressed from WOQL queries, the following function allow users to explicitly select the graph being queried: . .using() .from() and .quad() allow users to specify graph filters for queries | .into() .detete_quad() and .add_quad() allow users to specify graph identifiers for updates. | . Setting Graph Filters for Queries . Graph filters either identify a specific graph by id (type/id) or identify all of a specific type of graph with a wildcard schema/*. So, for example, the Query WOQL.quad(&quot;v:A&quot;, &quot;v:B&quot;, &quot;v:C&quot;, &quot;schema/*&quot;) Will find all triples in all schema graphs for the current database. . We can achieve the same effect with the from() function: WOQL.from(&quot;schema/*&quot;).triple(&quot;v:A&quot;, &quot;v:B&quot;, &quot;v:C&quot;) . Or the using() function (which allows us to specify any graph on the server - in any branch or db) WOQL.using(&quot;account/dbid/master/main/graph/schema/*&quot;).triple(&quot;v:A&quot;, &quot;v:B&quot;, &quot;v:C&quot;) . Note that the default usage of WOQL.triple() is in fact just WOQL.from(&quot;instance/*&quot;).triple() or WOQL.quad(,,,&quot;instance/*&quot;) . Setting Graph Identifiers for Updates . Functions which update graphs need to provide a specific graph identifier (e.g. schema/main, instance/main) and cannot use wildcards (because we need to know which specific graph to update). Otherwise, the use of graph identifiers is identifical to graph filters: . WOQL.into(&quot;schema/main&quot;).add_triple() WOQL.add_quad(&quot;a&quot;, &quot;p&quot;, &quot;c&quot;, &quot;schema/main&quot;) WOQL.delete_quad(&quot;a&quot;, &quot;p&quot;, &quot;c&quot;, &quot;schema/main&quot;) . Creating and Deleting Graphs . The TerminusDB API has endpoints for creating and deleting instance, schema and inference graphs. The Schema Page of the TerminusDB Console also allows users to view, create and delete graphs. . WOQL.js . WOQLClient.createGraph(&quot;schema&quot;, &quot;xdd&quot;, &quot;Adding XDD Library Graph&quot;) WOQLClient.createGraph(&quot;inference&quot;, &quot;magic&quot;, &quot;Creating Dynamic Properties&quot;) WOQLClient.deleteGraph(&quot;inference&quot;, &quot;magic&quot;, &quot;Thought better of it&quot;) . Special Internal Graphs . In addition to the schema, instance and inference graphs within each database, each TerminusDB database contains two special graphs that contain the metadata about the graph structure and can be queried just like any other graph. . The two special graphs are the commits graph which contains a record of all commits and branches that have been created in the history of the database, and a repository graph which contains a record of the origin of the graph, most importantly local and remote repository metadata which enables controlled remote collaboration. In almost all circumstances, these graphs should not be directly updated except by the databases internal processes. However it is often useful to be able to query these graphs. . Commits Graph . The commits graph is addressed as &lt;accountid&gt;/&lt;dbid&gt;/&lt;repoid&gt;/_commits Where accountid/dbid identifies the specific database, identifies the repository within the database (e.g. local | remote) as different repo versions can have different commit historiers. . The below example queries the commits graph to find the first and last commit in the master branch. . The ref ontology defines the schema for the commit graph. . WOQL.using(&quot;me/mydb/local/_commits&quot;).and( WOQL.triple(&quot;v:Branch&quot;, &quot;ref:branch_name&quot;, &quot;master&quot;), WOQL.triple(&quot;v:Branch&quot;, &quot;ref:branch_base_uri&quot;, &quot;v:Base_URI&quot;), WOQL.opt().triple(&quot;v:Branch&quot;, &quot;ref:ref_commit&quot;, &quot;v:Head&quot;), WOQL.opt().triple(&quot;v:Head&quot;, &quot;ref:commit_id&quot;, &quot;v:HeadID&quot;), WOQL.opt().triple(&quot;v:Head&quot;, &quot;ref:commit_timestamp&quot;, &quot;v:Last&quot;), WOQL.opt().and( WOQL.path(&quot;v:Head&quot;, &quot;ref:commit_parent+&quot;, &quot;v:Tail&quot;, &quot;v:Path&quot;), WOQL.not().triple(&quot;v:Tail&quot;, &quot;ref:commit_parent&quot;, &quot;v:Any&quot;), WOQL.triple(&quot;v:Tail&quot;, &quot;ref:commit_id&quot;, &quot;v:TailID&quot;), WOQL.triple(&quot;v:Tail&quot;, &quot;ref:commit_timestamp&quot;, &quot;v:First&quot;) ) ) . Repository Graph . The Repository Graph contains details about the distributed nature of the database. Each database is stored as a local repository and zero or more remote repositories, which represent the state of the database as seen through the various different versions that track each other. This allows the definition of complex dependencies between distributed teams. .",
    "url": "/docs/user-guide/schema/graphs/",
    "relUrl": "/user-guide/schema/graphs/"
  }
  ,"21": {
    "title": "TerminusHub",
    "content": "TerminusHub . . Hub is Coming Soon | . Hub is Coming Soon . .",
    "url": "/docs/user-guide/hub/",
    "relUrl": "/user-guide/hub/"
  }
  ,"22": {
    "title": "IDs, IRIs, URLs and Prefixes",
    "content": "IDs in TerminusDB - IRIs, URLs and Prefixes . . Introduction | Predefined Namespace Prefixes | User Defined URIs | Extended Prefixes | ID Generation idgen &amp; unique | | . Introduction . Under the hood, TerminusDB uses RDF triples to store all it’s data. In RDF, all ids are defined to be IRIs - which can be thought of as URLs for all practical purposes. The benefits of using URLs as your principle IDs are many - you have a universal addressing space, which can be made automatically dereferencable and in complex data integration projects, namespaces are critical if we want to avoid undesirable naming collisions. . The disadvantages of using URLs for IDs are, firstly, URLs tend to be long and difficult to remember and secondly, that you have to put some effort into the process of figuring out how to generate good URLs to represent you data. . To address the first issue. rather than using full URLs, it’s much more convenient to express things in a compressed form, with prefixes that map to an IRI base providing namespace safety, with fragment ids which identify the particular unit. So for example, rather than writing . http://www.w3.org/1999/02/22-rdf-syntax-ns#type we can use rdf:type . Each TerminusDB database comes preconfigured with a configurable and extensible set of namespace prefixes. . To address the second issue, WOQL provides several functions which help with generating new ids. . Predefined Namespace Prefixes . The following URL prefixes are pre-configured (and fixed) for every TerminusDB Database: . &quot;@context&quot;:{ &quot;owl&quot;:&quot;http://www.w3.org/2002/07/owl#&quot;, &quot;rdf&quot;:&quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;, &quot;rdfs&quot;:&quot;http://www.w3.org/2000/01/rdf-schema#&quot;, &quot;xsd&quot;:&quot;http://www.w3.org/2001/XMLSchema#&quot; &quot;xdd&quot;:&quot;http://terminusdb.com/schema/xdd#&quot;, &quot;terminus&quot;:&quot;http://terminusdb.com/schema/terminus#&quot;, &quot;ref&quot;:&quot;http://terminusdb.com/schema/ref#&quot;, &quot;repo&quot;:&quot;http://terminusdb.com/schema/repository#&quot;, &quot;vio&quot;:&quot;http://terminusdb.com/schema/vio#&quot;, &quot;woql&quot;:&quot;http://terminusdb.com/schema/woql#&quot;, &quot;layer&quot;:&quot;http://terminusdb.com/schema/layer#&quot;, } . owl, rdf, rdfs, xsd, xdd are language primitives and datatypes. | ref, repo and layer refer to entities within the terminus layered storage system. | woql refers to the web object query language | terminus defines high level constructs such as databases and resources specific to the terminus db administration db. | . User Defined URIs . In addition to the built in URL prefixes which are fixed, each database has it’s own namespace. This defines two important features - firstly the URLs which will be used to represent the instance data and secondly the namespace that will be used to represent classes and properties that are local to the specific database. . Each terminus DB database has two useful prefixes defined by default. doc: is the default prefix that will be used for instance data in the database. TerminusDB allows users to define this to be whatever URL they want. So, for example, we can create a document with id “doc:John” and define the databases base uri to be “http://my.endpoint.com/” so that the data is actually stored and consumed as http://my.endpoint.com/John . The prefix is specified in the create database api call and can be changed on a per-branch level, with different prefixes applying to different branch and can be specified during branch creation. . WOQLClient.createDatabase({uri_prefix: &quot;http://my.data.com/&quot;}) . Extended Prefixes . Users can add new prefixes to a database, to conveniently support imported rdf data which may use a variety of namespaces and URLs. This can be achieved through the schema section of the console or through the following API call. . Does not exist yet . ID Generation . When inserting data, it is frequently the case that we need to generate new ids to represent the new objects that we are writing to the database. In general, we can always use the doc: prefix for all data objects which provides us with local namespace safety as well as potential universal addressability. However, this still leaves the case of the appropriate local extension to use for each object within the database. How should we form our doc:something ids? . TerminusDB puts no restrictions on the IDs that are used for any object. As long as the id is unique within that database (and is a valid id without spaces or colons), it is valid. In the case of datasets where each entity has an existing unique identifier, we can choose to simply use these ids directly as is and that will work fine. However, in the more general case, where we can generate new ids for the entities in our database, the choice of which ids to use is signficant for several important reasons. Firstly, it is always quicker to lookup a value by its doc:id than it is search for it by the value of one of its properties - so when we first generate a new unique ID it pays to consider how easy it will be to regenerate that ID automatically without having to look it up. Secondly, without some principled way of naming objects, we quickly get to a situation where we have namespace clashes and confusion about types (we may, for example, have a Wine and a Person object both with the id: “doc:Rose”). . In the case of schema and inference graphs, we are normally dealing with a small enough number of entities that it is normally possible to name them individually without too much risk of namespace collisions. However, in general, in terminusDB we use the naming convention where we use capital letters (CamelCase) for class names and lowercase with underscores (snake_case) for property names. We encourage the use of this convention to guard against confusion. . When it comes to instance data, TerminusDB provides two functions in WOQL that are explicitly concerned with generating unique ids for new objects in the database. They allow users to reliably generate unique identifiers for objects from input variables with the guarantee that the functions will always produce the same output IDs when given the same input identifiers. The trick to using these functions is to find input variables that suitably make the value unique while being widely enough available to be likely useful in future situations where you want to generate the IDs again. For example, a customers name and address might be good choices. . The second assistance that TerminusDB offers is the use of a convention whereby all objects ids should include the most-specific-class id in the name, so, for example, rather than using the id: doc:Rome, we would use the id doc:City_Rome to avoid later namespace collisions, and to include more information within the id/URL itself. . The two functions that generate IDs in WOQL are idgen and unique. . idgen &amp; unique . WOQL.idgen(&quot;doc:City&quot;, [&quot;v:Name&quot;, &quot;v:State&quot;, &quot;v:Country&quot;], &quot;v:CityID&quot;) WOQL.unique(&quot;doc:Person&quot;, [&quot;v:FirstName&quot;, &quot;v:Family_Name&quot;, &quot;v:DOB&quot;], &quot;v:PersonID&quot;) .",
    "url": "/docs/user-guide/schema/ids/",
    "relUrl": "/user-guide/schema/ids/"
  }
  ,"23": {
    "title": "Getting started",
    "content": "Getting started . This session will have new users to start using TerminusDB. .",
    "url": "/docs/getting-started",
    "relUrl": "/getting-started"
  }
  ,"24": {
    "title": "User guide",
    "content": "User guide . This session documents details about TerminusDB for users. .",
    "url": "/docs/user-guide",
    "relUrl": "/user-guide"
  }
  ,"25": {
    "title": "Home",
    "content": "TerminusDB Documentation . Documentation for TerminusDB - an open-source graph database that stores data like git. . Get started now View it on GitHub . . . Getting started . Dependencies . Docker | Git | . Quick start: install with docker . Get the script in the terminusdb-quickstart repo, cd to it . git clone https://github.com/terminusdb/terminusdb-quickstart cd terminusdb-quickstart . Run the container (the first time) . ./terminusdb-container run Unable to find image &#39;terminusdb/terminusdb-server:latest&#39; locally latest: Pulling from terminusdb/terminusdb-server 8f91359f1fff: Pulling fs layer 939634dec138: Pulling fs layer f30474226dd6: Pulling fs layer 32a63113e3ae: Pulling fs layer ae35de9092ce: Pulling fs layer 023c02983955: Pulling fs layer d9fa4a1acf93: Pulling fs layer [ ... ] . For details, go to Quick install with docker . . About the project . ©2020 - TerminusDB. . License . TerminusDB is Distributed by an &lt;a href=&quot;https://github.com/terminusdb/terminusdb-server/blob/master/LICENSE&quot;&gt;GPL-3.0 license.&lt;/a&gt;. . Contributing . Read more about becoming a contributor in Developer Guide. . Thank you to the contributors! . . Code of Conduct . TerminusDB is committed to an inclusive and welcoming community. Please follow Berlin Code of Conduct. .",
    "url": "/docs/",
    "relUrl": "/"
  }
  ,"26": {
    "title": "Inserting Data",
    "content": "Inserting Data . . Loading Data into Database Loading Data into a Temporary Graph loading data from csv | loading data from RDF | loading data from local file | | Insert Data into Graph Database | | Loading Data into Database . Loading data into a graph, usually involve in two stages: . loading data into a temporary graph | insert the data into the graph according to the schema | . Though using the WOQLjs or WOQLpy programatically to insert data is also possible. . Loading Data into a Temporary Graph . loading data from csv . Loading data form csv involve in getting the data from the csv and wrangling the data. First, read in the data form the csv and assign variables corresponding to each column. . csv = WOQL.get( WOQL.as(&quot;Start station&quot;,&quot;v:Start_Station&quot;) .as(&quot;End station&quot;, &quot;v:End_Station&quot;) .as(&quot;Start date&quot;, &quot;v:Start_Time&quot;) .as(&quot;End date&quot;, &quot;v:End_Time&quot;) .as(&quot;Duration&quot;, &quot;v:Duration&quot;) .as(&quot;Start station number&quot;, &quot;v:Start_ID&quot;) .as(&quot;End station number&quot;, &quot;v:End_ID&quot;) .as(&quot;Bike number&quot;, &quot;v:Bike&quot;) .as(&quot;Member type&quot;, &quot;v:Member_Type&quot;) ).remote(url); . The above will read a csv form a remote destination url (e.g. a file hosted online) and assigning variable to each column. The variables will be is used in the data wrangling: . wrangles = [ WOQL.idgen(&quot;doc:Journey&quot;,[&quot;v:Start_ID&quot;,&quot;v:Start_Time&quot;,&quot;v:Bike&quot;],&quot;v:Journey_ID&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:Start_ID&quot;],&quot;v:Start_Station_URL&quot;), WOQL.cast(&quot;v:Duration&quot;, &quot;xsd:integer&quot;, &quot;v:Duration_Cast&quot;), WOQL.cast(&quot;v:Bike&quot;, &quot;xsd:string&quot;, &quot;v:Bike_Label&quot;), WOQL.cast(&quot;v:Start_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:Start_Time_Cast&quot;), WOQL.cast(&quot;v:End_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:End_Time_Cast&quot;), WOQL.cast(&quot;v:Start_Station&quot;, &quot;xsd:string&quot;, &quot;v:Start_Station_Label&quot;), WOQL.cast(&quot;v:End_Station&quot;, &quot;xsd:string&quot;, &quot;v:End_Station_Label&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:End_ID&quot;],&quot;v:End_Station_URL&quot;), WOQL.idgen(&quot;doc:Bicycle&quot;,[&quot;v:Bike_Label&quot;],&quot;v:Bike_URL&quot;), WOQL.concat(&quot;v:Start_ID to v:End_ID at v:Start_Time&quot;,&quot;v:Journey_Label&quot;), WOQL.concat(&quot;Bike v:Bike from v:Start_Station to v:End_Station at v:Start_Time until v:End_Time&quot;,&quot;v:Journey_Description&quot;) ]; . Three common data wrangling methods are: idgen(), cast() and concat(): . idgen creates unique identifier for each data object, there are 3 arguments needed: 1. the prefix; 2. the list of columns to generate the identifier, and; 3. the variable to store the identifier. | cast is used to change the datatype, for data that are not strings, it is needed to convert the incoming data to their correct datatypes. | concat is used to create new strings with the variables, just like formatted strings in JavaScript and Python. | . Then the two steps can be combined with a WOQL.and(): . inputs = WOQL.and(csv, ...wrangles); . loading data from RDF . Instead of data wrangling, data form RDF can be loaded directly to a temporary graph: . WOQL.with(&quot;graph://temp&quot;, WOQL.remote(&quot;my_url&quot;, {&quot;type&quot;:&quot;turtle&quot;}), WOQL.quad(&quot;v:Subject&quot;, &quot;v:Predicate&quot;, &quot;v:Object&quot;, &quot;graph://temp&quot;) ) . from the temporary graph, we can insert the data according to the schema of the designated graph database. See this blog post for more details/ . loading data from local file . In the above example, we assume the data source is hosted online with a url to pass in for WOQL.remote(). For a local file, we use WOQL.file() instead. Refer to this blog post for using local files with TerminusDB Docker images. . Insert Data into Graph Database . Either the data is in the temporary graph or is processed by JavaScript or Python program, eventually it has to be insert into the graph database. It is done with WOQL.insert(), usage could be: . inserts = WOQL.and( WOQL.insert(&quot;v:Journey_ID&quot;, &quot;Journey&quot;) .label(&quot;v:Journey_Label&quot;) .description(&quot;v:Journey_Description&quot;) .property(&quot;start_time&quot;, &quot;v:Start_Time_Cast&quot;) .property(&quot;end_time&quot;, &quot;v:End_Time_Cast&quot;) .property(&quot;duration&quot;, &quot;v:Duration_Cast&quot;) .property(&quot;start_station&quot;, &quot;v:Start_Station_URL&quot;) .property(&quot;end_station&quot;, &quot;v:End_Station_URL&quot;) .property(&quot;journey_bicycle&quot;, &quot;v:Bike_URL&quot;), WOQL.insert(&quot;v:Start_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:Start_Station_Label&quot;), WOQL.insert(&quot;v:End_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:End_Station_Label&quot;), WOQL.insert(&quot;v:Bike_URL&quot;, &quot;Bicycle&quot;) .label(&quot;v:Bike_Label&quot;) ); . WOQL.insert() takes two arguments: 1. the id for the object, could be the variables from data wrangles or a string generated form your program; 2. the type of the object, it should be the doctype form the schema. label, description and property can be added to the object in a similar manor as creating schema. . Example of using WOQLjs and WOQLpy to load the insert data form csvs can be found in this GitHub repo. Example of programatically creating schema and inserting data directly from WOQLpy can be found in this GitHub repo. . To complete loading in the data, the previous steps need to be join together with inserts using a WOQL.and(). For example loading data from csv: . WOQL.and(csv, ...wrangles, inserts) . .",
    "url": "/docs/user-guide/query/inserting-data/",
    "relUrl": "/user-guide/query/inserting-data/"
  }
  ,"27": {
    "title": "Installation of JS/ Python Clients",
    "content": "Installation of JS/ Python Clients . . Javascript Client Requirements | Installation NPM Module | Minified Script | | | Python Client Requirements | Installation | | . Javascript Client . Requirements . TerminusDB | NodeJS 8.1.4+ | . Installation . Terminus Client can be used as either a Node.js module available through the npm registry, or directly included in web-sites by including the script tag below. . NPM Module . Before installing, download and install Node.js. Node.js 0.10 or higher is required. . Installation is done using the npm install command: . Using npm: . $ npm install --save @terminusdb/terminusdb-client . Minified Script . Using cdn: . &lt;script src=&quot;https://unpkg.com/@terminusdb/terminusdb-client/dist/terminusdb-client.min.js&quot;&gt;&lt;/script&gt; . Downloading: . Download the terminusdb-client.min.js file from the /dist directory and save it to your location of choice, then: . &lt;script src=&quot;http://my.saved.location/terminusdb-client.min.js&quot;&gt;&lt;/script&gt; . JavaScript Client Documentaiton . . Python Client . Note that this Python Client works with TerminusDB v1.0. Python Client for new version coming soon. . Requirements . TerminusDB | Python &gt;= 3.6 | . Installation . Terminus Client Python can be download form PyPI using pip: . python -m pip install terminusdb-client-python . this only include the core Python Client and WOQLQuery. . If you want to use woqlDataframe: . python -m pip install terminusdb-client-python[dataframe] . if you are installing form zsh you have to quote the argument like this: . python -m pip install &#39;terminusdb-client-python[dataframe]&#39; . Install from source: . python -m pip install git+https://github.com/terminusdb/terminusdb-client-python.git . Python Client Documentation .",
    "url": "/docs/getting-started/install-clients/",
    "relUrl": "/getting-started/install-clients/"
  }
  ,"28": {
    "title": "Intro to graph data modelling",
    "content": "TerminusDB Graph Basics . TerminusDB organises data in a very simple structure to make it easy and natural to model the real world. . Whereas traditional relational databases divide data into tables, columns and rows, in terminusDB everything is an object - objects can have properties and some of these properties may link to other objects. The network of interlinked objects forms a graph structure (in the mathematical sense - nodes and edges). . This is the basic idea of the graph database - using data structures that are things rather than cells allows users to create models that are much closer to the real world things that they want to model - because people perceive the world as things, not cells. . To explain with a very simple example - if we were building a database to hold a family tree and we want to record the parents and grand-parents of an individual. In a relationsal database, we might record this in a simple table . Person_ID Name DOB mother father . 1 | John | 1/10/79 | 2 | 3 | . 2 | Mary | 4/2/56 | 4 | 5 | . 3 | John snr | 28/11/52 | 6 | 7 | . 4 | Patricia | 17/4/22 | null | null | . 5 | Michael | 1/9/09 | null | null | . 6 | Sally | 17/4/23 | null | null | . 7 | Robert | 3/10/13 | null | null | . In a graph database, this would look like the following . . The big advantage is that it is much easier to interpret the model and understand how it maps to real world entities compared to the relational example. This increased ease also extends to querying the database. . #Query For example, if we wanted to fetch the name of john’s mother and grandmother from the database, if we were using a relational database, we could use the following two SQL queries to get the name of the mother and grandmother respectively: . SELECT Name from TABLE where Person_ID = (SELECT mother from TABLE where Name=&quot;John&quot;) SELECT Name from TABLE where Person_ID = (SELECT mother from TABLE WHERE Person_ID = (SELECT mother from TABLE where Name=&quot;John&quot;)) . In a graph database this is much simpler: we can use a triple pattern such as the following to get both names in the same query - we do not have to explicitly join the records together, the joins are implicit - we use the same ID in different parts of the query: . WOQL.and( WOQL.triple(&quot;v:Person&quot;, &quot;mother&quot;, &quot;v:MotherID&quot;), WOQL.triple(&quot;v:MotherID&quot;, &quot;name&quot;, &quot;v:MotherName&quot;), WOQL.triple(&quot;v:MotherID&quot;, &quot;mother&quot;, &quot;v:GrandmotherID&quot;), WOQL.triple(&quot;v:GrandmotherID&quot;, &quot;name&quot;, &quot;v:GrandmotherName&quot;), ) . By using “v:MotherID” multiple times in the query, we create a chain: v:Person =mother=&gt; v:Mother =mother=&gt; v:Grandmother . This makes our queries much easier to understand - we can follow them naturally across multiple patterns. . Classes &amp; Properties . Under the hood, Terminus DB uses a very rich data modelling language called OWL - the Web Ontology Language. Although it is a very rich language, the basic ideas are simple. . In our schema we can define classes - which are definitions of types of complex data structure. Classes can be subclasses of other classes, which means that they inherit all the parent’s definitions (much like inheritance in object oriented programming). We can also define properties in the schema - each property has a domain (the class that is the subject of the property) and a range - the type of data that the property points to. The range can either be a simple datatype literal (e.g. an integer or string) or it can be a class. . For most use cases, that’s all you really need to know. You define a hierarchy of classes to represent the different types of things that you want to represent in your database, then you define properties to represent the different attributes of these things that you want to record and the relationships between the things. From these simple building blocks - class hierarchies and typed properties, you can build almost arbitrarily complex data structures to represent whatever real world entities you are interested in. .",
    "url": "/docs/getting-started/intro-graph/",
    "relUrl": "/getting-started/intro-graph/"
  }
  ,"29": {
    "title": "JSON-LD Query",
    "content": "JSON-LD Query . . WOQL - Web Object Query Language | WOQL JSON-LD Encoding | WOQL - Web Object Query Language . The WOQL query language is a unified model query language. It allows us to treat our database as a document store or a graph interchangeably, and provides powerful query features which make relationship traversals easy. . WOQL’s interchange format is written in JSON-LD. This gives us a relatively straightforward human-readable format which can also be easily stored in TerminusDB itself. . For example a simple query which returns every source, predicate and object in a database: . {&quot;@context&quot; : {&quot;@import&quot;: &quot;https://terminusdb/contexts/woql/syntax/context.jsonld&quot;, &quot;@propagate&quot;: true}, &quot;@type&quot; : &quot;Triple&quot;, &quot;subject&quot; : {&quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : {&quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Subject&quot;}}, &quot;predicate&quot; : {&quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : {&quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Predicate&quot;}}, &quot;object&quot; : {&quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : {&quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Object&quot;}}} . This format is relatively verbose and inconvenient to write directly. However it is ideal for constructing programmatically in Python, Javascript or whatever your favourite language is. It’s also possible to represent queries as graphs in Terminus, thereby allowing you to store and load queries which belong with your datasets. . . WOQL JSON-LD Encoding . The default imported JSON-LD context at https://terminusdb/contexts/woql/syntax/context.jsonld allows the syntax to be less verbose by automatically adding “@base”, assuming that bare words are in the WOQL namespace. In addition some parameters of keywords are assumed to be identifiers and not strings. . {&quot;@context&quot; : {&quot;@version&quot;: 1.0, &quot;@base&quot;: &quot;http://terminusdb.com/schema/woql&quot;, &quot;@vocab&quot; : &quot;#&quot;, &quot;rdf&quot; : &quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;, &quot;rdfs&quot; : &quot;http://www.w3.org/2000/01/rdf-schema#&quot;, &quot;tcs&quot; : &quot;http://terminusdb.com/schema/tcs#&quot;, &quot;owl&quot; : &quot;http://www.w3.org/2002/07/owl#&quot;, &quot;xsd&quot; : &quot;http://www.w3.org/2001/XMLSchema#&quot;, &quot;v&quot; : &quot;http://terminusdb.com/schema/woql/variable/&quot;, &quot;terminus&quot; : &quot;http://terminusdb.com/schema/terminus#&quot;, &quot;query_list&quot; : {&quot;@type&quot; : &quot;@id&quot;}, &quot;query&quot; : {&quot;@type&quot; : &quot;@id&quot;}, ... } } . .",
    "url": "/docs/user-guide/query/json-ld/",
    "relUrl": "/user-guide/query/json-ld/"
  }
  ,"30": {
    "title": "Managing Databases",
    "content": "Managing Database . This interface allows you to create a new database in 2 ways. . Create New Database . Creates a fresh new empty database. You can choose weather you want to create this new database locally or in Terminus Hub. Note that in order to create a database on TerminusDB.com you will need to be logged in. . Copy Database . Allows you to Copy from another existing database from a remote server or your local machine. You can also choose weather you want to fork or clone from existing database. You can choose to create a copy of an existing database locally or on TerminusDB.com .",
    "url": "/docs/user-guide/console/managing-databases/",
    "relUrl": "/user-guide/console/managing-databases/"
  }
  ,"31": {
    "title": "Managing Documents",
    "content": "Code . . Inline code | Syntax highlighted code blocks | Code blocks with rendered examples | . Inline code . Code can be rendered inline by wrapping it in single back ticks. . Lorem ipsum dolor sit amet, &lt;inline code snippet&gt; adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. . Lorem ipsum dolor sit amet, `&lt;inline code snippet&gt;` adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. . . Syntax highlighted code blocks . Use Jekyll’s built-in syntax highlighting with Rouge for code blocks by using three backticks, followed by the language name: . // Javascript code with syntax highlighting. var fun = function lang(l) { dateformat.i18n = require(&#39;./lang/&#39; + l) return true; } . js // Javascript code with syntax highlighting. var fun = function lang(l) { dateformat.i18n = require(&#39;./lang/&#39; + l) return true; } . . Code blocks with rendered examples . To demonstrate front end code, sometimes it’s useful to show a rendered example of that code. After including the styles from your project that you’ll need to show the rendering, you can use a &lt;div&gt; with the code-example class, followed by the code block syntax. If you want to render your output with Markdown instead of HTML, use the markdown=&quot;1&quot; attribute to tell Jekyll that the code you are rendering will be in Markdown format… This is about to get meta… . Link button . [Link button](http://example.com/){: .btn } . &lt;div class=&quot;code-example&quot; markdown=&quot;1&quot;&gt; [Link button](http://example.com/){: .btn } &lt;/div&gt; markdown [Link button](http://example.com/){: .btn } .",
    "url": "/docs/user-guide/console/managing-documents/",
    "relUrl": "/user-guide/console/managing-documents/"
  }
  ,"32": {
    "title": "Managing DB Schemas",
    "content": "Managing Schemas . This Interface allows User to understand and manage schema. TerminusDB supports database with multiple schemas. . Classes . This tab displays a table of classes available in the database schema . Properties . This tab displays a table of all available properties in the database . OWL . This tab displays an Ontology of the Schema. User is able to edit and update the schema in this area. On Success the new database will be working according to the updated schema. If there were any VIO errors then this attempt will not succeed and user will have to adhere to the VIO rules. . Note: A select with available graphs such as Inference graph, Schema graph for database can be toggled to view their OWLs respectively . Graphs . Here you can create and manage different types of graph such as Schema, Inference or Instance graphs. . URL Prefixes . Provides you with a table which shows the value of prefixes being used in TerminusDB. .",
    "url": "/docs/user-guide/console/managing-schemas/",
    "relUrl": "/user-guide/console/managing-schemas/"
  }
  ,"33": {
    "title": "Merging",
    "content": "Merging . . Merge Strategies Rebase | | . Merge Strategies . Currently we have only implemented a single strategy for merging branches. This strategy is called rebase. We intend to include other approaches to merge in the near future. . Rebase . . Rebase is a merge style which takes the commits from a source branch and places all new commits (those which follow from the common history of it exists) on the top of the current head. This allows users to create a common view of history which plays new work on top of that which has already been commited by others. This can be convenient when collaborating with other users. .",
    "url": "/docs/user-guide/revision-control/merging/",
    "relUrl": "/user-guide/revision-control/merging/"
  }
  ,"34": {
    "title": "The Meta Graph",
    "content": "The Meta Graph . . Coming Soon | . Coming Soon .",
    "url": "/docs/user-guide/revision-control/meta-graph/",
    "relUrl": "/user-guide/revision-control/meta-graph/"
  }
  ,"35": {
    "title": "Other ways of installing TerminusDB",
    "content": "Other ways of installing TerminusDB . . Linux Debian or Ubuntu Rust | SWIPL | Terminus Server | | Fedora or Red Hat Rust | SWIPL | SWIPL libraries | Terminus Server | | Arch Linux Rust | Library dependencies | SWIPL libraries | Terminus Server | | | . Linux . This page covers the process of manually building TerminusDB on various Linux distributions. . Debian or Ubuntu . The following directions should work on Debian or Ubuntu. . Rust . Install Rust by following the following instructions on the official Rust installation guide. . SWIPL . To use Terminus Server, you will need the SWIPL installation of Prolog. To install this in Debian variants simply use the apt package manager: . apt install swi-prolog . Once installed, you will have to install two library dependencies from SWIPL. . This can be done by typing: . $ swipl Welcome to SWI-Prolog (threaded, 64 bits, version 8.1.10-28-g8a26a53c1) SWI-Prolog comes with ABSOLUTELY NO WARRANTY. This is free software. Please run ?- license. for legal details. For online help and background, visit http://www.swi-prolog.org For built-in help, use ?- help(Topic). or ?- apropos(Word). 1 ?- pack_install(terminus_store_prolog). % Contacting server .... . Terminus Server . The Terminus Server source tree should then be cloned from GitHub: . git clone https://github.com/terminusdb/terminusdb-server cd terminusdb-server git submodule init git submodule update . You need to set the admin user password which is used as a super-user API key for access. This can be done with the db_init script. The script should also be used to configure the server name, as shown in the example. . utils/db_init -k &quot;my_password_here&quot; -s &quot;my_server_name_here&quot; . At this point you can enter the terminusDB directory and start the server: . ./start.pl . Now you are ready to interact with the HTTP server. . Fedora or Red Hat . These instructions have been tested on Fedora 30 and might result in different results depending on your Fedora / Red Hat release. . Rust . Install Rust by following the following instructions on the official Rust installation guide. . SWIPL . SWI-Prolog is needed to run terminusdb-server. Install SWI-PROLOG with: . sudo dnf install pl pl-devel . SWIPL libraries . Run SWIPL and install the required dependencies, note that you need to have rust installed to compile the dependencies: . $ swipl Welcome to SWI-Prolog (threaded, 64 bits, version 8.1.10-28-g8a26a53c1) SWI-Prolog comes with ABSOLUTELY NO WARRANTY. This is free software. Please run ?- license. for legal details. For online help and background, visit http://www.swi-prolog.org For built-in help, use ?- help(Topic). or ?- apropos(Word). 1 ?- pack_install(terminus_store_prolog). % Contacting server .... . Terminus Server . The Terminus Server source tree should then be cloned from GitHub: . git clone https://github.com/terminusdb/terminusdb-server cd terminusdb-server git submodule init git submodule update . You need to set the admin user password which is used as a super-user API key for access. This can be done with the db_init script. The script should also be used to configure the server name, as shown in the example. . utils/db_init -k &quot;my_password_here&quot; -s &quot;my_server_name_here&quot; . At this point you can enter the terminusDB directory and start the server: . ./start.pl . Now you are ready to interact with the HTTP server. . Arch Linux . Rust . Install Rust by following the following instructions on the official Rust installation guide. . Library dependencies . Install all dependencies of all the required libraries: | sudo pacman -S git swi-prolog make automake autoconf libtool zlib pkgconf gcc . SWIPL libraries . Run SWIPL and install the required dependencies, note that you need to have rust installed to compile the dependencies: . $ swipl Welcome to SWI-Prolog (threaded, 64 bits, version 8.1.10-28-g8a26a53c1) SWI-Prolog comes with ABSOLUTELY NO WARRANTY. This is free software. Please run ?- license. for legal details. For online help and background, visit http://www.swi-prolog.org For built-in help, use ?- help(Topic). or ?- apropos(Word). 1 ?- pack_install(terminus_store_prolog). % Contacting server .... . Terminus Server . The Terminus Server source tree should then be cloned from GitHub: . git clone https://github.com/terminusdb/terminusdb-server cd terminusdb-server git submodule init git submodule update . You need to set the admin user password which is used as a super-user API key for access. This can be done with the db_init script. The script should also be used to configure the server name, as shown in the example. . utils/db_init -k &quot;my_password_here&quot; -s &quot;my_server_name_here&quot; . At this point you can enter the terminusDB directory and start the server: . ./start.pl . Now you are ready to interact with the HTTP server. .",
    "url": "/docs/getting-started/other-install/",
    "relUrl": "/getting-started/other-install/"
  }
  ,"36": {
    "title": "Package overview",
    "content": "Introduction . TerminusDB consists of a large number of different code-repositories and packages, each of which is made available individually on the TerminusDB github page, as well as being bundled into releases. This document describes the different packages and what they do and why you might need them. . Core Server Packages . These packages are part of the core TerminusDB DB Server engine . terminusdb-server . The main server package - built in Prolog - contains much of the logic and orchestration of the system . terminusdb-store . The underlying data store - built in Rust - provides fast access to an immutable append only data-store . jwt_io . JWT authentication support for Prolog - used by terminusdb-server to enable JWT authentication . terminus_store_prolog . Prolog bindings which allow Terminus Server to talk to terminusdb-store . terminusdb-store-test . Automated load testing scripts for terminusdb-store . terminusdb-upgrade-to-store . Old package to support upgrading from terminusdb-server 1.0 to terminusdb-server 1.1 - requiring a change in underlying storage engine from HDT to terminusdb-store . Client Language Packages . Client libraries for accessing TerminusDB from programming languages . terminusdb-client . Javascript client library - comes as npm model or script . terminusdb-client-python . Python client library - includes panda dataframes integration. . User Interface . User Interface libraries for visualising TerminusDB contents and query results . terminusdb-console . The management dashboard that ships with TerminusDB . terminusdb-react-table . A react table element for displaying TerminusDB query results . terminusdb-react-graph . A react graph element based on d3, for displaying TerminusDB query results as graphs . terminusdb-react-chart . A react charting element, for displaying TerminusDB query results as charts . Documentation and News . Repositories which provide documentation and news about TerminusDB . terminusdb-doc . The documentation site for terminus DB - includes this page! . terminusdb-tutorials . A collection of tutorials and useful scripts to help users better understand TerminusDB . terminusdb-schema . Documentation on the internal datastructures used by TerminusDB . terminusdb-blog . The TerminusDB blog site . terminusdb-community . The TerminusDB community website . terminusdb-events . The TerminusDB events listing site . documentation-sprint . Special repository for supporting documentation sprints . terminusdb-knowledge . Some background articles on terminus DB . Deployment . Repositories to help deploy TerminusDB . terminusdb-quickstart . Quickstart script for loading TerminusDB as a docker container . terminusdb-heroku . One click deploy of TerminusDB to a heroku account. . katacoda-scenarios . TerminusDB deployed as a katacode tutorial (Deprecated as service has become tumbleweed) . swi-prolog-docker . Docker container pre-built for SWI-Prolog .",
    "url": "/docs/getting-started/package-overview/",
    "relUrl": "/getting-started/package-overview/"
  }
  ,"37": {
    "title": "Properties",
    "content": "Schema Properties in TerminusDB . . Introduction Property ID | Property Type | Property Label | Property Description | Property Domain | Property Range | Property Cardinality Constraints | | Examples Simple Datatype Property WOQL.js | WOQL.py | OWL (turtle encoding) | | Simple Object Property WOQL.js | WOQL.py | OWL (turtle encoding) | | Datatype Property with Cardinality Constraints WOQL.js | WOQL.py | OWL (turtle encoding) | | Datatype Property with Cardinality Constraints WOQL.js | WOQL.py | OWL (turtle encoding) | | | . Introduction . In a TerminusDB schema, there are objects, defined by classes, and these objects can have attributes associated with them which are defined by proprties in the schema. . There are 7 important parts to a property definition: . Property ID | Property Type | Property Label | Property Description | Property Domain | Property Range | Property Cardinality Constraints | Property ID . Under the hood TerminusDB uses OWL and RDF for defining Schemas. In RDF, all ids are IRIs and this is the case with property IDs, like all IDs in TerminusDB. However, rather than using full URLs, it’s much more convenient to express things in a compressed form, with prefixes that map to an IRI base providing namespace safety, with fragment ids which identify the particular class. So for example, rather than writing . http://terminusdb.com/john/crm#address . it’s much more convenient to write: . crm:address - and define the crm prefix to map to the actual URL. . In TerminusDB, a predefined prefix is part of every database - the scm namespace is local to every database and allows you to create a class that is local to that database, with a valid IRI which will not clash with any other namespaces. In general, unless you know what you are doing, you should always just use the scm: prefix for all your properties. . In TerminusDB we generally follow the convention that property names are all lower case and use snake-case to make compound property names: word1_word2 . In most cases, in TerminusDB you won’t need to specify the prefix - if you are using the default scm: prefix, it will be automatically added when no prefix is supplied. You just need to choose an id for your property that is meaningful, if possible according to the naming convention above. Because the property ID forms part of an IRI, you cannot use spaces in property ids, other special characters are permitted but should be used with extreme caution. . Property Type . Properties are divided into two distinct types - datatype properties and object properties. Datatype properties point at simple literal types - strings, numbers and so on, while object properties point at structured objects. In our schema definition we specify the type of the property, and the types of the objects which can appear on the left (domain) and the right (range) of the property. If the property is a Datatype property, the range will always be a datatype, if the property is an object property, the range will always be a class. In all cases, the domain of a property must be a class. . Property Label . Like classes, properties can have a label - a simple text string that can be used in UI elements to refer to the property. This uses the standard rdfs:label predicate. Labels are optional but strongly recommended. . Property Description . Properties can also have a description defined in the schema - a longer text string describing the meaning or rationale of the property. Providing descriptions is good practice as it provides readable documentation for others who want to understand the schema. Under the hood, descriptions are encoded using the standard rdfs:comment predicate. Descriptions are optional but strongly recommended. . Property Domain . The domain of a property is the class that can be considered to ‘own’ the property - that is to say that the domain of a property appears on the left hand side of the triple that uses the property. So, for example, if I have a property called color with a domain of Car, then an object of type car can have a color property associated with it. This uses the standard rdfs:domain predicate under the hood. . Property Range . The range of the value is the class or datatype that can be considered to represent the value of the property. For example, if my color property is defined as having a range of ‘xsd:string’ this means that the value of the property must be a string. If, on the other hand, it is defined as being an instance of a defined ‘Color’ class, then this means that the value should be an object of type Color. This uses the standard rdfs:range predicate under the hood. . Property Cardinality Constraints . Properties can have cardinality constraints associated with them. The semantics of these constraints are simple. We can define a maximum cardinality, a minimum cardinality or an exact cardinality for any property in the schema and this will be enforced by the system - in that TerminusDB will prevent you from writing any data to the database that breaks the cardinality constraints. So, for example, if I define a property to have a cardinality of exactly one, then if I create an object of a class that is the domain of this property, I must provide exactly one value for this property or it will be rejected - this is a mandatory and unique property. Similarly, if I define a property to have a maximum cardinality of 1, then the property is unique but not mandatory and if I define a property as having a minimum cardinality of 1, then it is a mandatory but not necessarily unique property. . Under the hood, OWL has a non-intuitive way of defining such restrictions, although it is mathematically precise, using inheritance from a special owl:Restriction. Some example are provided below. . Examples . Simple Datatype Property . Defining a color property for a Car which takes a string value (e.g. “red”) . WOQL.js . WOQL.add_property(&quot;color&quot;, &quot;string&quot;) .label(&quot;Color&quot;) .description(&quot;The color of the object&quot;) .domain(&quot;Car&quot;) . WOQL.py . WOQLQuery().add_property(&quot;color&quot;, &quot;string&quot;) .label(&quot;Color&quot;) .description(&quot;The color of the object&quot;) .domain(&quot;Car&quot;) . OWL (turtle encoding) . scm:color a owl:DatatypeProperty; rdfs:label &quot;Color&quot;@en; rdfs:comment &quot;The color of the object&quot;@en; rdfs:domain scm:Car rdfs:range xsd:string. . Simple Object Property . Defining an address property for a Person which takes a structured Address object . WOQL.js . WOQL.add_property(&quot;address&quot;, &quot;Address&quot;) .label(&quot;Address&quot;) .description(&quot;The postal address at which the person lives&quot;) .domain(&quot;Person&quot;) . WOQL.py . WOQLQuery().add_property(&quot;address&quot;, &quot;Address&quot;) .label(&quot;Address&quot;) .description(&quot;The postal address at which the person lives&quot;) .domain(&quot;Person&quot;) . OWL (turtle encoding) . scm:address a owl:ObjectProperty; rdfs:label &quot;Address&quot;@en; rdfs:comment &quot;The postal address at which the person lives&quot;@en; rdfs:domain scm:Person rdfs:range scm:Address. . Datatype Property with Cardinality Constraints . Defining a social security number property for a Person which is mandatory and unique . WOQL.js . WOQL.add_property(&quot;ssn&quot;, &quot;integer&quot;) .label(&quot;SSN&quot;) .description(&quot;An official social security number&quot;) .domain(&quot;Person&quot;) .cardinality(1) . WOQL.py . WOQLQuery().add_property(&quot;ssn&quot;, &quot;integer&quot;) .label(&quot;SSN&quot;) .description(&quot;An official social security number&quot;) .domain(&quot;Person&quot;) .cardinality(1) . OWL (turtle encoding) . In OWL we have to make the domain class a subclass of the restriction to encode the constraint. . scm:ssn a owl:ObjectProperty; rdfs:label &quot;SSN&quot;@en; rdfs:comment &quot;An official social security number&quot;@en; rdfs:domain scm:Person rdfs:range xsd:integer. scm:ssn_property_constraint a owl:Restriction; owl:onProperty scm:ssn; owl:cardinality 1^^xsd:nonNegativeInteger. scm:Person a owl:Class; rdfs:subClassOf scm:ssn_property_constraint. . Datatype Property with Cardinality Constraints . Defining a rule that each employee must be assigned at least 3 tasks and no more than 5 tasks at any one time. . WOQL.js . WOQL.add_property(&quot;tasks&quot;, &quot;Task&quot;) .label(&quot;tasks&quot;) .description(&quot;A task assigned to an employee&quot;) .domain(&quot;Employee&quot;) .min(3) .max(5) . WOQL.py . WOQLQuery().add_property(&quot;tasks&quot;, &quot;Task&quot;) .label(&quot;Tasks&quot;) .description(&quot;A task assigned to an employee&quot;) .domain(&quot;Employee&quot;) .min(3) .max(5) . OWL (turtle encoding) . scm:tasks a owl:ObjectProperty; rdfs:label &quot;Tasks&quot;@en; rdfs:comment &quot;A task assigned to an employee&quot;@en; rdfs:domain scm:Employee rdfs:range scm:Task. scm:tasks_property_constraint a owl:Restriction; owl:onProperty scm:tasks; owl:minCardinality 5^^xsd:nonNegativeInteger; owl:maxCardinality 5^^xsd:nonNegativeInteger. scm:Task a owl:Class; rdfs:subClassOf scm:tasks_property_constraint. .",
    "url": "/docs/user-guide/schema/properties/",
    "relUrl": "/user-guide/schema/properties/"
  }
  ,"38": {
    "title": "Pull and Push",
    "content": "Pull and Push . . Coming Soon | . Coming Soon .",
    "url": "/docs/user-guide/revision-control/pull-push/",
    "relUrl": "/user-guide/revision-control/pull-push/"
  }
  ,"39": {
    "title": "Create TerminusDB Graph with Python Client",
    "content": "Create TerminusDB Graph with Python Client . Note that this tutorial is based on TerminusDB v1.0. Tutorial for new version coming soon. . In here you will see a step-by-step guide to create your first knowledge with Terminus DB Python Client in Jupyter notebook. We assume already have Jupyter notebook and TerminusDB Python Client (with woqlDataframe) installed and have TerminusDB up and running. . . Create a database | Create a Schema | Load in the Data Get csvs into variables | Data wrangles | Insert Query | Combine the 3 and load the csvs | | Query The Data | Graph Visualisation | . Create a database . First, import WOQLClient, WOQLQuery and query_to_df form the client library: . from woqlclient import WOQLClient from woqlclient import WOQLQuery from woqlclient import query_to_df . Then set up server_url and key for the client. For a local database, it’s “http://localhost:6363” and “root” by default. Here we use the docker image of TerminusDB. . We also need a database id and a name for the database: . server_url = &quot;http://localhost:6363&quot; key = &quot;root&quot; dbId = &quot;pybike&quot; db_name = &quot;Bicycle Graph&quot; . After that, create a WOQLClient object and use connect() and createDatabase(). . client = WOQLClient() client.connect(server_url, key) client.createDatabase(dbId, db_name) . Go to the console, we should now have the database created. . . Create a Schema . To create a schema, we construct a WOQLQuery object schema that will create a schema and use execute() to pass this query to TerminusDB via the client that we set up in the previous step. . def create_schema(client): &quot;&quot;&quot;The query which creates the schema Parameters - it uses variables rather than the fluent style as an example ========== client : a WOQLClient() connection &quot;&quot;&quot; schema = WOQLQuery().when(True).woql_and( WOQLQuery().doctype(&quot;Station&quot;). label(&quot;Bike Station&quot;). description(&quot;A station where bikes are deposited&quot;), WOQLQuery().doctype(&quot;Bicycle&quot;).label(&quot;Bicycle&quot;), WOQLQuery().doctype(&quot;Journey&quot;).label(&quot;Journey&quot;). property(&quot;start_station&quot;, &quot;Station&quot;).label(&quot;Start Station&quot;). property(&quot;end_station&quot;, &quot;Station&quot;).label(&quot;End Station&quot;). property(&quot;duration&quot;, &quot;integer&quot;).label(&quot;Journey Duration&quot;). property(&quot;start_time&quot;, &quot;dateTime&quot;).label(&quot;Time Started&quot;). property(&quot;end_time&quot;, &quot;dateTime&quot;).label(&quot;Time Ended&quot;). property(&quot;journey_bicycle&quot;, &quot;Bicycle&quot;).label(&quot;Bicycle Used&quot;) ) return schema.execute(client) create_schema(client) . To review this schema-building WOQL query: . The when will perform the operation for every time its first argument is True. In this case, exactly once. | We perform all operations within the and. | So here’s the operations we have performed: . We created three different document types (given by the doctype function): Station , Journey and Bicycle | We added label (names) or description (short descriptions) to them. | We created properties for Journey, we do that by using the property function after Journey with the first argument as the name of the property and the second argument as the type (or range) of the property. | For each property, you have to provide an id and the type of that property in property, as with class you can add a label to it as well. | Go to the console, check that you have successfully created the schema by clicking the Schema button on the left. You should now be able to see the classes and properties in table format and get a graph representation by clicking the ‘graph’ button (circled in red): . . . . . . Load in the Data . Assume we have a list of csvs that we would like to load. . csvs = [ &quot;https://terminusdb.com/t/data/bikeshare/2011-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2012Q1-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2010-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2012Q2-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2012Q3-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2012Q4-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2013Q1-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2013Q2-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2013Q3-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2013Q4-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2014Q1-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2014Q2-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2014Q3-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2014Q4-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2015Q1-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2015Q2-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2015Q3-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2015Q4-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2016Q1-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2016Q2-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2016Q3-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2016Q4-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2017Q1-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2017Q2-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2017Q3-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/2017Q4-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201801_capitalbikeshare_tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201802-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201803-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201804-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201805-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201806-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201807-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201808-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201809-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201810-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201811-capitalbikeshare-tripdata.csv&quot;, &quot;https://terminusdb.com/t/data/bikeshare/201812-capitalbikeshare-tripdata.csv&quot; ] . These are hosted on a server, for . The process of loading csvs consist of 3 parts: . reading the csvs in a temporary space and assign variables to them | perform data wrangles which prepare the data in the temporary space fit for our schema | insert the inputs into the graph database according to the schema. | . Get csvs into variables . def get_csv_variables(url): &quot;&quot;&quot;Extracting the data from a CSV and binding it to variables Parameters ========== client : a WOQLClient() connection url : string, the URL of the CSV &quot;&quot;&quot; csv = WOQLQuery().get( WOQLQuery().woql_as(&quot;Start station&quot;, &quot;v:Start_Station&quot;). woql_as(&quot;End station&quot;, &quot;v:End_Station&quot;). woql_as(&quot;Start date&quot;, &quot;v:Start_Time&quot;). woql_as(&quot;End date&quot;, &quot;v:End_Time&quot;). woql_as(&quot;Duration&quot;, &quot;v:Duration&quot;). woql_as(&quot;Start station number&quot;, &quot;v:Start_ID&quot;). woql_as(&quot;End station number&quot;, &quot;v:End_ID&quot;). woql_as(&quot;Bike number&quot;, &quot;v:Bike&quot;). woql_as(&quot;Member type&quot;, &quot;v:Member_Type&quot;) ).remote(url) return csv . This function consist the part of the query that imports the data from CSV in a const variable named csv. Then we create a list of WOQL operators and save it in another constvariable called wrangles, we combine the two parts of the query with a woql_and operator. . Data wrangles . def get_wrangles(): wrangles = [ WOQLQuery().idgen(&quot;doc:Journey&quot;, [ &quot;v:Start_ID&quot;, &quot;v:Start_Time&quot;, &quot;v:Bike&quot;], &quot;v:Journey_ID&quot;), WOQLQuery().idgen(&quot;doc:Station&quot;, [ &quot;v:Start_ID&quot;], &quot;v:Start_Station_URL&quot;), WOQLQuery().cast(&quot;v:Duration&quot;, &quot;xsd:integer&quot;, &quot;v:Duration_Cast&quot;), WOQLQuery().cast(&quot;v:Bike&quot;, &quot;xsd:string&quot;, &quot;v:Bike_Label&quot;), WOQLQuery().cast(&quot;v:Start_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:Start_Time_Cast&quot;), WOQLQuery().cast(&quot;v:End_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:End_Time_Cast&quot;), WOQLQuery().cast(&quot;v:Start_Station&quot;, &quot;xsd:string&quot;, &quot;v:Start_Station_Label&quot;), WOQLQuery().cast(&quot;v:End_Station&quot;, &quot;xsd:string&quot;, &quot;v:End_Station_Label&quot;), WOQLQuery().idgen(&quot;doc:Station&quot;, [&quot;v:End_ID&quot;], &quot;v:End_Station_URL&quot;), WOQLQuery().idgen(&quot;doc:Bicycle&quot;, [&quot;v:Bike_Label&quot;], &quot;v:Bike_URL&quot;), WOQLQuery().concat(&quot;Journey from v:Start_ID to v:End_ID at v:Start_Time&quot;, &quot;v:Journey_Label&quot;), WOQLQuery().concat(&quot;Bike v:Bike from v:Start_Station to v:End_Station at v:Start_Time until v:End_Time&quot;, &quot;v:Journey_Description&quot;) ] return wrangles . The wrangles is a list of WOQLQuery objects. They use 3 WOQL functions to transform the data into the correct form for input. In each case, the function creates a new variable as output — the last argument in each case. The idgen function generates IDs for our three document types Journey, Station, and Bicycle. The first argument is the prefix that will be used, the second is a list of variables which combine to give a unique identity for the id. For example, in Journey we use 3 fields in the csv (Start_ID, Start_Time and Bike) to generate a unique id Journey_ID. . Besides generating IDs, we also create new fields with new data types, for example, we use typecast to cast Duration into integer and store it as Duration_Cast. We can also use concat to contract new text formatted with variables in the fields — for example, to create Journey_Label. . Insert Query . def get_inserts(): inserts = WOQLQuery().woql_and( WOQLQuery().insert(&quot;v:Journey_ID&quot;, &quot;Journey&quot;). label(&quot;v:Journey_Label&quot;). description(&quot;v:Journey_Description&quot;). property(&quot;start_time&quot;, &quot;v:Start_Time_Cast&quot;). property(&quot;end_time&quot;, &quot;v:End_Time_Cast&quot;). property(&quot;duration&quot;, &quot;v:Duration_Cast&quot;). property(&quot;start_station&quot;, &quot;v:Start_Station_URL&quot;). property(&quot;end_station&quot;, &quot;v:End_Station_URL&quot;). property(&quot;journey_bicycle&quot;, &quot;v:Bike_URL&quot;), WOQLQuery().insert(&quot;v:Start_Station_URL&quot;, &quot;Station&quot;). label(&quot;v:Start_Station_Label&quot;), WOQLQuery().insert(&quot;v:End_Station_URL&quot;, &quot;Station&quot;). label(&quot;v:End_Station_Label&quot;), WOQLQuery().insert(&quot;v:Bike_URL&quot;, &quot;Bicycle&quot;). label(&quot;v:Bike_Label&quot;) ) return inserts . This is the part of the query that actually inserts the data into the structure that we defined on our schema. . The insert function inserts a new node into the database with the id Journey_ID and type Journey we add properties like start_time, end_time, duration, start_station, end_station and label and put the variables produced above in their correct spots. | For Start_Station_URL, End_Station_URL and Bike_URL, we assign a type and label for each of them. | . Combine the 3 and load the csvs . def load_csvs(client, csvlist, wrangl, insert): &quot;&quot;&quot;Load the CSVs as input Parameters ========== client : a WOQLClient() connection csvs : a dict of all csvs to be input &quot;&quot;&quot; for url in csvlist: csv = get_csv_variables(url) inputs = WOQLQuery().woql_and(csv, *wrangl) answer = WOQLQuery().when(inputs, insert) answer.execute(client) load_csvs(client, csvs, get_wrangles(), get_inserts()) . Here, for each url in the list above (a list named csvs) we combine the result of get_csv_variables and result of get_wrangles with a woql_and and called it inputs. When the inputs are ready, perform get_inserts. . . Query The Data . def query_data(client): &quot;&quot;&quot;The query which query the database Parameters - it uses variables rather than the fluent style as an example ========== client : a WOQLClient() connection &quot;&quot;&quot; conditions = [WOQLQuery().triple(&quot;v:Journey&quot;, &quot;type&quot;, &quot;scm:Journey&quot;), WOQLQuery().triple(&quot;v:Journey&quot;, &quot;start_station&quot;, &quot;v:Start&quot;), WOQLQuery().opt().triple(&quot;v:Start&quot;, &quot;label&quot;, &quot;v:Start_Label&quot;), WOQLQuery().triple(&quot;v:Journey&quot;, &quot;end_station&quot;, &quot;v:End&quot;), WOQLQuery().opt().triple(&quot;v:End&quot;, &quot;label&quot;, &quot;v:End_Label&quot;), WOQLQuery().triple(&quot;v:Journey&quot;, &quot;journey_bicycle&quot;, &quot;v:Bike&quot;)] query = WOQLQuery().select(&quot;v:Start&quot;, &quot;v:Start_Label&quot;, &quot;v:End&quot;, &quot;v:End_Label&quot;).woql_and(*conditions) return query.execute(client) result = query_data(client) . Here we used select to filter out the variables (those starting with v:) that appear in our output. Then we used and to link all the conditions we want to include, as you can see there are lot’s of triples to be conditioned. The ones with opt() means that they are optional — it will be ignored if that data is missing (instead of returning an error — very handy). . The query can be translated as below: . select all the Journeys | and all the start_stations of all the Journeys (let’s call them Start) | and, if any, all the labels of the start_stations (let’s call them Start_Label) | and all the end_stations of all the Journeys (let’s call them End) | and, if any, all the labels of the end_stations (let’s call them End_Label) | and all the journey_bicycles of all the Journeys (let’s call them Bike) | Note that we store the result as a variable which can be used with query_to_df to turn it into a pandas DataFrame . query_to_df(result) . . . Graph Visualisation . Graph Visualisation can be created in the TerminusDB console, please see the Graph Visualisation session at Create TerminusDB Graph with Console. .",
    "url": "/docs/getting-started/start-tutorials/py_client/",
    "relUrl": "/getting-started/start-tutorials/py_client/"
  }
  ,"40": {
    "title": "Query",
    "content": "Query . WOQL is the query language that works with TerminusDB. With its Prolog like logic, it is an elegant way to query data when you get the hang of it. . WOQL’s primary syntax and interchange format is in JSON-LD. However, you can use WOQLjs and WOQLpy package which is included in their corresponding API client to construct WQOL queries. Query using WOQLjs and WOQLpy is also available in TerminusDB console. . . WOQL - Web Object Query Language | WOQL JSON-LD Encoding | WOQLjs and WOQLpy | Creating Schema Document objects | Properties | Subclases | | Loading Data into Database Loading Data into a Temporary Graph loading data from csv | loading data from RDF | loading data from local file | | Insert Data into Graph Database | | Querying Database Query at Console | WOQLpy - Getting Result as a Pandas DataFrame | | . WOQL - Web Object Query Language . The WOQL query language is a unified model query language. It allows us to treat our database as a document store or a graph interchangeably, and provides powerful query features which make relationship traversals easy. . WOQL’s interchange format is written in JSON-LD. This gives us a relatively straightforward human-readable format which can also be easily stored in TerminusDB itself. . For example a simple query which returns every source, predicate and object in a database: . {&quot;@context&quot; : {&quot;@import&quot;: &quot;https://terminusdb/contexts/woql/syntax/context.jsonld&quot;, &quot;@propagate&quot;: true}, &quot;@type&quot; : &quot;Triple&quot;, &quot;subject&quot; : {&quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : {&quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Subject&quot;}}, &quot;predicate&quot; : {&quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : {&quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Predicate&quot;}}, &quot;object&quot; : {&quot;@type&quot; : &quot;Variable&quot;, &quot;variable_name&quot; : {&quot;@type&quot; : &quot;xsd:string&quot;, &quot;@value&quot; : &quot;Object&quot;}}} . This format is relatively verbose and inconvenient to write directly. However it is ideal for constructing programmatically in Python, Javascript or whatever your favourite language is. It’s also possible to represent queries as graphs in Terminus, thereby allowing you to store and load queries which belong with your datasets. . . WOQL JSON-LD Encoding . The default imported JSON-LD context at https://terminusdb/contexts/woql/syntax/context.jsonld allows the syntax to be less verbose by automatically adding “@base”, assuming that bare words are in the WOQL namespace. In addition some parameters of keywords are assumed to be identifiers and not strings. . {&quot;@context&quot; : {&quot;@version&quot;: 1.0, &quot;@base&quot;: &quot;http://terminusdb.com/schema/woql&quot;, &quot;@vocab&quot; : &quot;#&quot;, &quot;rdf&quot; : &quot;http://www.w3.org/1999/02/22-rdf-syntax-ns#&quot;, &quot;rdfs&quot; : &quot;http://www.w3.org/2000/01/rdf-schema#&quot;, &quot;tcs&quot; : &quot;http://terminusdb.com/schema/tcs#&quot;, &quot;owl&quot; : &quot;http://www.w3.org/2002/07/owl#&quot;, &quot;xsd&quot; : &quot;http://www.w3.org/2001/XMLSchema#&quot;, &quot;v&quot; : &quot;http://terminusdb.com/schema/woql/variable/&quot;, &quot;terminus&quot; : &quot;http://terminusdb.com/schema/terminus#&quot;, &quot;query_list&quot; : {&quot;@type&quot; : &quot;@id&quot;}, &quot;query&quot; : {&quot;@type&quot; : &quot;@id&quot;}, ... } } . . WOQLjs and WOQLpy . JSON, through an elegant way to pass queries to the database, it is not the most coding friendly. WOQLjs and WOQLpy provide a tool to construct WOQL queries with JavaScript and Python. They are included in their corresponding API client to construct WQOL queries. Query using WOQLjs and WOQLpy is also available in TerminusDB console. For details about WOQLjs and WOQLpy calls, please see the documentation of the API clients: . JavaScript ClientPython Client . We assume most users will use WOQLjs or WOQLpy when constructing queries, hence most examples in this documentation will be in WOQLjs and/or WOQLpy. . . Creating Schema . Schema can be constructed by creating doctype follow by its property (if any), each of them can have its own label and discription. for example in WOQLjs: . WOQL.and( WOQL.doctype(&quot;Station&quot;) .label(&quot;Bike Station&quot;) .description(&quot;A station where bicycles are deposited&quot;), WOQL.doctype(&quot;Bicycle&quot;) .label(&quot;Bicycle&quot;), WOQL.doctype(&quot;Journey&quot;) .label(&quot;Journey&quot;) .property(&quot;start_station&quot;, &quot;Station&quot;) .label(&quot;Start Station&quot;) .property(&quot;end_station&quot;, &quot;Station&quot;) .label(&quot;End Station&quot;) .property(&quot;duration&quot;, &quot;integer&quot;) .label(&quot;Journey Duration&quot;) .property(&quot;start_time&quot;, &quot;dateTime&quot;) .label(&quot;Time Started&quot;) .property(&quot;end_time&quot;, &quot;dateTime&quot;) .label(&quot;Time Ended&quot;) .property(&quot;journey_bicycle&quot;, &quot;Bicycle&quot;) .label(&quot;Bicycle Used&quot;) ) . Document objects . The executable queries can be constructed with the help of the WOQL query objects. Usually there document objects with labels and descriptions can be easily constructed with a chain of call like: . WOQL.doctype(&quot;Station&quot;) .label(&quot;Bike Station&quot;) .description(&quot;A station where bicycles are deposited&quot;) . However, labels and descriptions are optional. The minimum way of creating a document object would be WOQL.doctype(&quot;idOfObj&quot;) . Properties . Properties can also be chained to the document objects in WOQLjs and WOQLpy, for example in WOQLjs: . WOQL.doctype(&quot;Journey&quot;) .label(&quot;Journey&quot;) .property(&quot;start_station&quot;, &quot;Station&quot;) .label(&quot;Start Station&quot;) . Properties will take an extra argument for the range of the property - it could be a datatype e.g. dateTime, string, integer, double, etc; or an other document object. label and descriptions can also be added to properties in similar manner as doctype objects. . Subclases . To created a subclass structure in TerminusDB graph,add_quad can be used. For example: . WOQL.add_quad(&quot;child&quot;, &quot;subClassOf&quot;, &quot;parent&quot;, &quot;schema&quot;) . For details regarding WOQL query objects in API clients, please refer to API Reference . . Loading Data into Database . Loading data into a graph, usually involve in two stages: . loading data into a temporary graph | insert the data into the graph according to the schema | . Though using the WOQLjs or WOQLpy programatically to insert data is also possible. . Loading Data into a Temporary Graph . loading data from csv . Loading data form csv involve in getting the data from the csv and wrangling the data. First, read in the data form the csv and assign variables corresponding to each column. . csv = WOQL.get( WOQL.as(&quot;Start station&quot;,&quot;v:Start_Station&quot;) .as(&quot;End station&quot;, &quot;v:End_Station&quot;) .as(&quot;Start date&quot;, &quot;v:Start_Time&quot;) .as(&quot;End date&quot;, &quot;v:End_Time&quot;) .as(&quot;Duration&quot;, &quot;v:Duration&quot;) .as(&quot;Start station number&quot;, &quot;v:Start_ID&quot;) .as(&quot;End station number&quot;, &quot;v:End_ID&quot;) .as(&quot;Bike number&quot;, &quot;v:Bike&quot;) .as(&quot;Member type&quot;, &quot;v:Member_Type&quot;) ).remote(url); . The above will read a csv form a remote destination url (e.g. a file hosted online) and assigning variable to each column. The variables will be is used in the data wrangling: . wrangles = [ WOQL.idgen(&quot;doc:Journey&quot;,[&quot;v:Start_ID&quot;,&quot;v:Start_Time&quot;,&quot;v:Bike&quot;],&quot;v:Journey_ID&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:Start_ID&quot;],&quot;v:Start_Station_URL&quot;), WOQL.cast(&quot;v:Duration&quot;, &quot;xsd:integer&quot;, &quot;v:Duration_Cast&quot;), WOQL.cast(&quot;v:Bike&quot;, &quot;xsd:string&quot;, &quot;v:Bike_Label&quot;), WOQL.cast(&quot;v:Start_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:Start_Time_Cast&quot;), WOQL.cast(&quot;v:End_Time&quot;, &quot;xsd:dateTime&quot;, &quot;v:End_Time_Cast&quot;), WOQL.cast(&quot;v:Start_Station&quot;, &quot;xsd:string&quot;, &quot;v:Start_Station_Label&quot;), WOQL.cast(&quot;v:End_Station&quot;, &quot;xsd:string&quot;, &quot;v:End_Station_Label&quot;), WOQL.idgen(&quot;doc:Station&quot;,[&quot;v:End_ID&quot;],&quot;v:End_Station_URL&quot;), WOQL.idgen(&quot;doc:Bicycle&quot;,[&quot;v:Bike_Label&quot;],&quot;v:Bike_URL&quot;), WOQL.concat(&quot;v:Start_ID to v:End_ID at v:Start_Time&quot;,&quot;v:Journey_Label&quot;), WOQL.concat(&quot;Bike v:Bike from v:Start_Station to v:End_Station at v:Start_Time until v:End_Time&quot;,&quot;v:Journey_Description&quot;) ]; . Three common data wrangling methods are: idgen(), cast() and concat(): . idgen creates unique identifier for each data object, there are 3 arguments needed: 1. the prefix; 2. the list of columns to generate the identifier, and; 3. the variable to store the identifier. | cast is used to change the datatype, for data that are not strings, it is needed to convert the incoming data to their correct datatypes. | concat is used to create new strings with the variables, just like formatted strings in JavaScript and Python. | . Then the two steps can be combined with a WOQL.and(): . inputs = WOQL.and(csv, ...wrangles); . loading data from RDF . Instead of data wrangling, data form RDF can be loaded directly to a temporary graph: . WOQL.with(&quot;graph://temp&quot;, WOQL.remote(&quot;my_url&quot;, {&quot;type&quot;:&quot;turtle&quot;}), WOQL.quad(&quot;v:Subject&quot;, &quot;v:Predicate&quot;, &quot;v:Object&quot;, &quot;graph://temp&quot;) ) . from the temporary graph, we can insert the data according to the schema of the designated graph database. See this blog post for more details/ . loading data from local file . In the above example, we assume the data source is hosted online with a url to pass in for WOQL.remote(). For a local file, we use WOQL.file() instead. Refer to this blog post for using local files with TerminusDB Docker images. . Insert Data into Graph Database . Either the data is in the temporary graph or is processed by JavaScript or Python program, eventually it has to be insert into the graph database. It is done with WOQL.insert(), usage could be: . inserts = WOQL.and( WOQL.insert(&quot;v:Journey_ID&quot;, &quot;Journey&quot;) .label(&quot;v:Journey_Label&quot;) .description(&quot;v:Journey_Description&quot;) .property(&quot;start_time&quot;, &quot;v:Start_Time_Cast&quot;) .property(&quot;end_time&quot;, &quot;v:End_Time_Cast&quot;) .property(&quot;duration&quot;, &quot;v:Duration_Cast&quot;) .property(&quot;start_station&quot;, &quot;v:Start_Station_URL&quot;) .property(&quot;end_station&quot;, &quot;v:End_Station_URL&quot;) .property(&quot;journey_bicycle&quot;, &quot;v:Bike_URL&quot;), WOQL.insert(&quot;v:Start_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:Start_Station_Label&quot;), WOQL.insert(&quot;v:End_Station_URL&quot;, &quot;Station&quot;) .label(&quot;v:End_Station_Label&quot;), WOQL.insert(&quot;v:Bike_URL&quot;, &quot;Bicycle&quot;) .label(&quot;v:Bike_Label&quot;) ); . WOQL.insert() takes two arguments: 1. the id for the object, could be the variables from data wrangles or a string generated form your program; 2. the type of the object, it should be the doctype form the schema. label, description and property can be added to the object in a similar manor as creating schema. . Example of using WOQLjs and WOQLpy to load the insert data form csvs can be found in this GitHub repo. Example of programatically creating schema and inserting data directly from WOQLpy can be found in this GitHub repo. . To complete loading in the data, the previous steps need to be join together with inserts using a WOQL.and(). For example loading data from csv: . WOQL.and(csv, ...wrangles, inserts) . . Querying Database . You can use both WOQLjs or WOQLpy to Query the data from the database. The following describe a few ways to do that and with the result presented in the console or as a Pandas DataFrame (WOQLpy) . Query at Console . Queries can be done within the console, just click on the Query button at the top for the queries windows: . . An example of Query in WOQLjs would be: . WOQL.select(&quot;v:Start&quot;, &quot;v:Start_Label&quot;, &quot;v:End&quot;, &quot;v:End_Label&quot;).and( WOQL.triple(&quot;v:Journey&quot;, &quot;type&quot;, &quot;scm:Journey&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;start_station&quot;, &quot;v:Start&quot;), WOQL.opt().triple(&quot;v:Start&quot;, &quot;label&quot;, &quot;v:Start_Label&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;end_station&quot;, &quot;v:End&quot;), WOQL.opt().triple(&quot;v:End&quot;, &quot;label&quot;, &quot;v:End_Label&quot;), WOQL.triple(&quot;v:Journey&quot;, &quot;journey_bicycle&quot;, &quot;v:Bike&quot;) ) . Multiple WOQL.triples are used to describe the relations of the objects in the graph. They are combined with a WOQL.and. WOQL.quad can be used in similar way if the graph of that triple needed to be specified. . Without the WOQL.select, all the variables, described with prefix v:, that matches with the relations will be returned as result. However, using WOQL.select can limit which variable are returned in the result. This can be used if some of the variables are intermediate links in the relations and not needed in the result. The result can be presented in wither table view or graph view. . WOQL.opt is used if that conditional is optional. In this example, both labels for the Start Station and End Stations are not required. Using opt would avoid getting an error if any labels are missing. . WOQLpy - Getting Result as a Pandas DataFrame . Only in python client for TerminusDB v1.0 . If dataframe option is chosen when installing terminusdb-client-python (details here) after executing the query with query.execute(client) a result binding is returned and it could be convert as a Pandas DataFrame by woql.query_to_df(result). See tutorial as example. . .",
    "url": "/docs/user-guide/query",
    "relUrl": "/user-guide/query"
  }
  ,"41": {
    "title": "Querying Database",
    "content": "Querying the Database . The Query page allows you to query the database and view results. A set of pre loaded queries are available to load and fire. . 1) Schema Queries: these includes queries related to schema as shown below 1.1) Show All Schema Elements 1.2) Show All Classes 1.3) Show Document Classes 1.4) Show All properties . 2) Data Queries: these includes queries related to actual instances or data of defines classes and properties in schema 2.1) A dropdown list of classes are provided which allows user to view all instances of the chosen class 2.2) A dropdown list of properties are provided which allows user to view all instances of the chosen property 2.3) Show All Data . 3) Show All Documents: these includes queries related to documents 3.1) Allows you to filter a document by its ID 3.2) Show All Documents . On choosing any of the above saved queries the Query Editor is auto loaded with the respective query. You can set limit, start and customize a query as per requirements. The results of the fired query appears in table view by default. The user is also provided with a view tool bar which allows to flick through different views of the result such as graph view etc. .",
    "url": "/docs/user-guide/console/querying-databases/",
    "relUrl": "/user-guide/console/querying-databases/"
  }
  ,"42": {
    "title": "Quick install with docker",
    "content": "Quick install with docker . . Prerequisites Docker | Git | Sudo | | Quick Start | If you’ve installed before | Using the console | To stop, attach, etc, see usage | Using the Enviroment | . Prerequisites . Docker . Since this script uses the TerminusDB Docker container, you need to have Docker running. . On Windows and Mac, Docker Desktop can be downloaded here . On Linux, use your distro’s package manager, or find more information here . Git . This script is distributed via GitHub, so you will need git to clone and update it, if you don’t already have git, you can download it here . Windows users should use the application “Git Bash” for all terminal commands described below, this application comes with Git for Windows. . Sudo . Sudo is optional. As letting unprivileged users run docker is insecure, this script uses sudo by default if it is available. . Most users will not need to do anything here, sudo is installed by default on Macs and many populer Linux distros such as Fedora, Red Hat, Debian, Ubuntu and Mint. Linux users who use minmal distros such as Archlinux, are advised to install sudo and confugure their sudoers file accordingly. . Windows users do not need to do anything here. . . Quick Start . Get the script in the terminusdb-quickstart repo, cd to it . git clone https://github.com/terminusdb/terminusdb-quickstart cd terminusdb-quickstart . Run the container (the first time) . ./terminusdb-container run Unable to find image &#39;terminusdb/terminusdb-server:latest&#39; locally latest: Pulling from terminusdb/terminusdb-server 8f91359f1fff: Pulling fs layer 939634dec138: Pulling fs layer f30474226dd6: Pulling fs layer 32a63113e3ae: Pulling fs layer ae35de9092ce: Pulling fs layer 023c02983955: Pulling fs layer d9fa4a1acf93: Pulling fs layer [ ... ] . . If you’ve installed before . You may need to move or remove previous volumes or you may encounter bugs or the old console. . Warning: This will lead to losing local data. . ./terminusdb-container rm removing will delete storage and config volumes Are you sure? [y/N] y terminus_storage terminusdb-config . . Using the console . Ready to terminate? Open the TerminusDB Console in your web browser. . ./terminusdb-container console . Or go here: http://localhost:6363/console . . To stop, attach, etc, see usage . ./terminusdb-container USAGE: terminusdb-container [COMMAND] help show usage run run container stop stop container console launch console in web browser attach attach to prolog shell stats show container stats rm-config remove config volume rm-storage remove storage volume rm remove volumes . That’s it! You’re ready to go! . . Using the Enviroment . Mount a local directory inside the container TERMINUSDB_LOCAL=/path/to/dir ./terminusdb-container [COMMAND] . | Using the latest release TERMINUSDB_TAG=latest ./terminusdb-container [COMMAND] . | Using the development release TERMINUSDB_TAG=dev ./terminusdb-container [COMMAND] . | Using a specific release instead of latest realease TERMINUSDB_TAG=v1.1.2 ./terminusdb-container [COMMAND] . | Not using sudo even when sudo is available TERMINUSDB_DOCKER=docker ./terminusdb-container [COMMAND] . | Using podman instead of docker command TERMINUSDB_DOCKER=&quot;podman&quot; ./terminusdb-container [COMMAND] . | . See the source code to find the other environment variables that can be set. .",
    "url": "/docs/getting-started/quick-install/",
    "relUrl": "/getting-started/quick-install/"
  }
  ,"43": {
    "title": "Release notes",
    "content": "Release notes . The various components of TerminusDB have different release notes. . terminusdb-server . TerminusDB Server Version 2.0 Release Notes . New . TerminusDB Server now implements databases as a tiered structure which tracks deltas on collections of graphs. This tiered structure includes: . Meta data graph: Holds information about the local and all remote repositories assocated with a given database. | Commit Graph: A graph containing information about all commits, their authors, a comment, and associated branches. | Instance and Schema Graphs: These graphs containing the actual data. | . These new structural changes to the underlying store allow users to perform a number of git-like operations. This includes: . Time-travel on databases: You can run queries, browse documents or view the schema at any previous commit. | Branching: You can branch from any current branch or reference (a previous commit). | . Several new querying capabilities have been added: . Regular path queries allowing the user to query recursively using combinations of intermediate predicates resulting in both end-point nodes and the particular path as a list of edge objects. | Database size and triple count can be queried | You can choose a specific resource to query including: the meta-data graph, the commit graph, a collection of instance or schema graphs, or a particular commit. | . Backwards-Incompatible Changes . The storage approach has changed dramatically and so previous databases can not be read directly by the new TerminusDB. Upgrades require re-ingesting data. . | The previous version of TerminusDB used JSON as an interchange for WOQL ASTs. The current version uses JSON-LD, which is a serialisation of RDF. This enables us to store WOQL queries in a database and provides a schema documentation of the WOQL query language. . | . Bug Fixes . Transactional logic in TerminusDB 1.0 had surprising outcomes when backtracking over inserts. We currently treat inserts as non-backtracking destructive updates. | WOQL.when is not required in order to perform updates. | . (TerminusDB Version 2.0 Release Notes)[https://github.com/terminusdb/terminusdb-server/commit/eaaf8d9eb2ddc01f5316c70e6cf66439f8b9797f] . terminusdb-client . TODO . terminusdb-client-python . TODO .",
    "url": "/docs/release_notes/",
    "relUrl": "/release_notes/"
  }
  ,"44": {
    "title": "Research",
    "content": "Gavin put your papers here please . . Inline code | Syntax highlighted code blocks | Code blocks with rendered examples | . Inline code . Code can be rendered inline by wrapping it in single back ticks. . Lorem ipsum dolor sit amet, &lt;inline code snippet&gt; adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. . Lorem ipsum dolor sit amet, `&lt;inline code snippet&gt;` adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. . . Syntax highlighted code blocks . Use Jekyll’s built-in syntax highlighting with Rouge for code blocks by using three backticks, followed by the language name: . // Javascript code with syntax highlighting. var fun = function lang(l) { dateformat.i18n = require(&#39;./lang/&#39; + l) return true; } . js // Javascript code with syntax highlighting. var fun = function lang(l) { dateformat.i18n = require(&#39;./lang/&#39; + l) return true; } . . Code blocks with rendered examples . To demonstrate front end code, sometimes it’s useful to show a rendered example of that code. After including the styles from your project that you’ll need to show the rendering, you can use a &lt;div&gt; with the code-example class, followed by the code block syntax. If you want to render your output with Markdown instead of HTML, use the markdown=&quot;1&quot; attribute to tell Jekyll that the code you are rendering will be in Markdown format… This is about to get meta… . Link button . [Link button](http://example.com/){: .btn } . &lt;div class=&quot;code-example&quot; markdown=&quot;1&quot;&gt; [Link button](http://example.com/){: .btn } &lt;/div&gt; markdown [Link button](http://example.com/){: .btn } .",
    "url": "/docs/research/",
    "relUrl": "/research/"
  }
  ,"45": {
    "title": "Resources",
    "content": "Resources . . Introduction | Collections References Branches | Commits | | Commit Graphs | Database Metadata | Resource string autocompletion | Relative resource strings The resource hierarchy | Building off the parent resource | Special considerations for branches and commits | | | Graphs Graph Filters | Graph Objects | | Introduction . In TerminusDB there are a number of different resources which can be refered to or manipulated by queries. These include the following: . Collections | References | Branches | Commits | Commit Graphs | Repository Metadata | Graphs | Graph Filters | Graph Objects | . In many different contexts we will have to describe the absolute or relative locations of these objects, and so we have resource identifiers which disambiguate which type of object we are referring to and where the system can find it. . Collections . A collection is a queryable object. However, not all collections are created equal. Some collections are read-only, and some are writable. . For instance, you can write to a branch, but it makes no sense to write to a commit, as a commit itself refers to a particular update. You can, however, query a commit to get back the data as it was at the time of that commit. . Collections are referred to using a path string. Inside of a query, you can use this string with the using keyword to query something different from your context. Outside of queries, you use these strings to set up your querying context, or refer to collections in any other operation that needs them. . Collection resource strings come in two forms: . absolute resource strings give an absolute path to the resource. | relative paths give a path relative to your current context. This generally only makes sense while querying with the using keyword. | . Let’s now go over all the collection types, and the resource string you’d use to refer to them. . References . References are currently either branches or commits. For some operations it is necessary to have a genuine branch (for instance, you can not update a commit), but for other operations either a branch or commit object will do. . Branches . &lt;account&gt;/&lt;dbid&gt;/&lt;repository&gt;/branch/&lt;branch_name&gt; . The following is the full name of a branch, including the account, database and repository in which it resides. . Commits . &lt;account&gt;/&lt;dbid&gt;/&lt;repository&gt;/commit/&lt;branch_name&gt; . This is the full reference to a commit. Using this reference will allow you to do things such as search at this commit, or rebase from this commit onto your current branch. . Commit Graphs . &lt;account&gt;/&lt;dbid&gt;/&lt;repository&gt;/_commits . The commit graph stores information about all commits that have been made in a given branch. You can query this to find information about historical updates, the author and time of these updates as well as which branches exist. . Database Metadata . &lt;account&gt;/&lt;dbid&gt;/_meta . The database metadata graph holds metadata about the entire database. This includes the default prefixes of this database, as well as all the local and remote repositories linked to this database. . Resource string autocompletion . Generally, incomplete resource strings will be autocompleted. The system generally assumes that you intend to access the master branch of the local repository of your database, so if you just specify an absolute resource string like . &lt;acount&gt;/&lt;dbid&gt; . The system will actually assume you meant . &lt;account&gt;/&lt;dbid&gt;/local/branch/master . Likewise, if you specify . &lt;account&gt;/&lt;dbid&gt;/origin . The system will assume you meant . &lt;account&gt;/&lt;dbid&gt;/origin/branch/master . Relative resource strings . While querying, it is possible to query other collections than the one in the current context with the using keyword. The using keyword takes a relative resource string. Failing to parse that as a valid relative string, it’ll try to parse it as an absolute resource string. . The resource hierarchy . To understand relative resource strings, it is helpful to consider the paths as a hierarchy. In order, this hierarchy consists of . the root | A user namespace | a database | a repository | a reference (branch or commit) | . For those resources lower in the hierarchy, it is possible for us to easily refer to any of the elements higher up in the hierarchy and build a path off that. Just like with absolute resource strings, they will get auto-completed. Suppose for example that you are currently working in joe/data/local/branch/work and you wish to query joe/data/origin/branch/master, you can do so using the path . _database/origin . Which gets resolved to . joe/data/origin . and then autocompleted to . joe/data/origin/branch/master . The full list of such keywords are . _root | _user | _database | _repository | . Building off the parent resource . In adition to the keywords described above, there’s also a special kind of path component, ... Just as in file paths, this path component gets you in the scope of a parent resource. For example, if your current context is joe/data/origin/branch/master and you specify the relative resource ../work, you’ll get joe/dasta/origin/branch/work. . Again, auto-completion applies. So if you are on joe/data/origin/branch/work and you lookup ../, it will autocomplete to joe/data/origin/branch/master. . Special considerations for branches and commits . since branches and commits don’t have any children of their own, as an extra convenience, relative lookups aren’t relative to the branch/commit, but relative to their repository. So for example, if you are currently on joe/data/origin/branch/master, you can specify branch/work or commit/commit_abcde or _commits, and they’ll be resolved in the context of the repository. . The one exception, as mentioned above, is .., which will be relative to the branch or commit, not relative to the repository. . Graphs . In the creation and deletion of graphs, as well as in querying (and especially inserting/deleting) it is necessary to refer to the precise graph which the user wants to update. We do this by specifying either graph filters or graph objects. . Graph Filters . &lt;type&gt;/&lt;name&gt; &lt;type&gt;/{&lt;name1&gt;,&lt;name2&gt;,...} &lt;type&gt;/* {&lt;type1&gt;,&lt;type2&gt;,...}/* {&lt;type1&gt;,&lt;type2&gt;,...} */* . A graph filter is a relative reference which allows the user to specify a collection of graphs from a given collection resource (generally the current query collection). The &lt;type&gt; must be drawn from the set {instance,schema,inference} which specifies precisely which variety of graph we are referring to. . We can either refer directly to the name of a graph, or some list of names or even just use the * as a wildcard. . The default filter that is used when no filter is specified will be instance/*. . Graph Objects . &lt;account&gt;/&lt;dbid&gt;/&lt;repository&gt;/branch/&lt;branch_name&gt;/&lt;type&gt;/&lt;graph_name&gt; &lt;account&gt;/&lt;dbid&gt;/&lt;repository&gt;/commit/&lt;commit_id&gt;/&lt;type&gt;/&lt;graph_name&gt; . A fully qualified graph object is referred to with its source branch name or commit id together with its type and name. . .",
    "url": "/docs/user-guide/query/resources/",
    "relUrl": "/user-guide/query/resources/"
  }
  ,"46": {
    "title": "Revision Control",
    "content": "Revision Control . TerminusDB contains a powerful query engine and API, but what makes it most unique, is its revision control capabilities which were built into the very core of how TerminusDB works. In the most technical terms, TerminusDB uses an immutable append only layered storage model where only state differences are stored, using a succinct delta-encoding mechanism. In simple terms, TerminusDB never changes anything - whenever you update the database, new values are created which shadow the old ones but you can always look behind the shadow and see what everything looked like before each and every update. The entire history of everything that has ever been in the database is retained and readily accessible. . Once you have a database engine that works like this, it becomes relatively easy and lightweight to provide the core revision control operations - branch, merge, push and pull (or some variation thereof) that practical revision control systems must provide. . This basic idea and much of the revision control functionality has been shamelessly borrowed from Git - the version control tool that has improved all of our lives immesurably as software engineers. Where we have gone beyond git is that TerminusDB is designed for data not code - specifically and most importantly, in addition to providing all of the revision control functionality that git provides, TerminusDB also supports fast queries over very large (multi-billion node) highly complex datasets with an extremely expressive and formally correct query and schema language. . By marrying the scale and querying capabilities of a modern in-memory graph database with the revision control functionality of git, we hope to provide relief to every engineer who ever looked at a pile of huge CSVs and said to themselves, “there must be a better way of doing this, if only there was a git for data”. .",
    "url": "/docs/user-guide/revision-control",
    "relUrl": "/user-guide/revision-control"
  }
  ,"47": {
    "title": "Schema Query",
    "content": "Schema Query . . Creating Schema Document objects | Properties | Subclases | | Creating Schema . Schema can be constructed by creating doctype follow by its property (if any), each of them can have its own label and discription. for example in WOQLjs: . WOQL.and( WOQL.doctype(&quot;Station&quot;) .label(&quot;Bike Station&quot;) .description(&quot;A station where bicycles are deposited&quot;), WOQL.doctype(&quot;Bicycle&quot;) .label(&quot;Bicycle&quot;), WOQL.doctype(&quot;Journey&quot;) .label(&quot;Journey&quot;) .property(&quot;start_station&quot;, &quot;Station&quot;) .label(&quot;Start Station&quot;) .property(&quot;end_station&quot;, &quot;Station&quot;) .label(&quot;End Station&quot;) .property(&quot;duration&quot;, &quot;integer&quot;) .label(&quot;Journey Duration&quot;) .property(&quot;start_time&quot;, &quot;dateTime&quot;) .label(&quot;Time Started&quot;) .property(&quot;end_time&quot;, &quot;dateTime&quot;) .label(&quot;Time Ended&quot;) .property(&quot;journey_bicycle&quot;, &quot;Bicycle&quot;) .label(&quot;Bicycle Used&quot;) ) . Document objects . The executable queries can be constructed with the help of the WOQL query objects. Usually there document objects with labels and descriptions can be easily constructed with a chain of call like: . WOQL.doctype(&quot;Station&quot;) .label(&quot;Bike Station&quot;) .description(&quot;A station where bicycles are deposited&quot;) . However, labels and descriptions are optional. The minimum way of creating a document object would be WOQL.doctype(&quot;idOfObj&quot;) . Properties . Properties can also be chained to the document objects in WOQLjs and WOQLpy, for example in WOQLjs: . WOQL.doctype(&quot;Journey&quot;) .label(&quot;Journey&quot;) .property(&quot;start_station&quot;, &quot;Station&quot;) .label(&quot;Start Station&quot;) . Properties will take an extra argument for the range of the property - it could be a datatype e.g. dateTime, string, integer, double, etc; or an other document object. label and descriptions can also be added to properties in similar manner as doctype objects. . Subclases . To created a subclass structure in TerminusDB graph,add_quad can be used. For example: . WOQL.add_quad(&quot;child&quot;, &quot;subClassOf&quot;, &quot;parent&quot;, &quot;schema&quot;) . For details regarding WOQL query objects in API clients, please refer to API Reference . .",
    "url": "/docs/user-guide/query/schema-query/",
    "relUrl": "/user-guide/query/schema-query/"
  }
  ,"48": {
    "title": "Schema",
    "content": "Code . . Introduction | Schema Definition Language | Schema Constructs Classes | Properties | Datatypes | IRIs, URLs, IDs and Prefixes | Graphs - Schema - Instance &amp; Inference | Advanced - OWL Unleashed | | . Introduction . Schemas are a very important part of TerminusDB. They allow you to define the shape that your data can take in such a way that TerminusDB will enforce the rules - preventing you from saving broken data to your database. . Having to define a schema for your data does impose a certain amount of cost in advance for users. However, in the long run, the trade off is very much worth it. The earlier in the process that you identify errors in your data, the cheaper and easier it is to fix those errors. If your database allows you to write any old data to it, it becomes very difficult and expensive to clean it up subsequently. Many RDF based databases suffer terribly from the problem of not having adequate schemas defined in advance, meaning that they are in practice ‘triple-soup’ - an unmanageable mess of fragments of data which have no defined shape and are almost useless in practice. Thus we are strong advocates of defining schemas in advance. Without a schema it’s not a real database, just a collection of random data fragments that have no defined interpretation. . However, in certain cases, this can be overkill - for example, when you are first experimenting with a new project, it can be considerably offputting to have to nail things down in advance - you don’t know what exact shape the data should take until you’ve tried out a few different options. Therefore, TerminusDB also supports schema-free databases which allow you to save any data without restrictions. This does limit the features of the system that you can use - for example, subsumption can only work if there is a defined class hierarchy in the schema. Thus, schema-free databases cannot use the more advanced features of the WOQL query language. Still they can be queried and written to using the basic structures of WOQL such as triple, path, etc. . . Schema Definition Language . Under the hood, TerminusDB uses OWL, the Web Ontology Language for defining its schema. OWL is a very rich and expressive language which allows you to encode a vast amount of business logic and rules in the schema itself. Furthermore, it has a solid mathematical basis, meaning that the definitions are precise and formally verifiable by reasoners. It is by some way, the most sophisticated data description standard that humankind has thus produced. However, it has a couple of major problems. Firstly, it lacks much in the way of tool support - using native OWL tools is a painful expreience. Secondly, it was defined as having only an ‘open world’ interpretation which is of limited use in practice. . Therefore, although TerminusDB uses OWL under the hood, our interpretation is a standard, ordinary closed world one when using it for schema checking. We also support open world interpretations, via an inference graph - which supports almost all of the sophisticated reasoning capabilities of the language. Furthermore, rather than using OWL directly, in TerminusDB we typically use our programming language query composers WOQL.js and WOQL.py for actually defining schemas. These hide a lot of the syntactic complexity of the language and allow you to define your schema in familiar ways, using simple syntax. . . Schema Constructs . Classes . In the TerminusDB schema, classes are used to define the shapes of the data structures that we store in the database. Every fragment of data saved in the database is associated with a particular type and this type is defined by it’s class definition in the schema. Classes are relatively simple structures - but they can be combined in a variety of ways to produce complex results. More . . Properties . In a TerminusDB schema, there are objects, defined by classes, and these objects can have attributes associated with them which are defined by proprties in the schema. TerminusDB provides a wide range of prebuilt property types. See More . . Datatypes . Not everything is an object. In addition to supporting sophisticated class and object hierarchies, TerminusDB also support a wide range of simple datatypes from the generic - strings, different types of numbers - to the advanced: built in coordinate data types, built-in uncertainty range primitive datatypes. Read More . . IRIs, URLs, IDs and Prefixes . If we want to easily integrate data from different sources, unique identifiers and namespaces are particularly useful - TerminusDB is based on OWL which uses RDF triples to store all data as IRIs. In most cases you won’t need to know the details of these IRIs and URLs that are used under the hood, but it is always useful to put some thought into choosing identifiers wisely and TerminusDB offers a lot of support for solving this problem. Read More . . Graphs - Schema - Instance &amp; Inference . Graphs (or Named Graphs) are internal structures that TerminusDB can use to segregate different parts of the database from one another. At the most basic level, TerminusDB has three types of graphs - instance graphs which are where we store ordinary data as RDF triples. Schema graphs are where we store rules governing the shape of the data while inference graphs are where we can encode complex runtime inference rules - both schema and inference graphs speak OWL. Read More . . Advanced - OWL Unleashed . TerminusDB supports a large fragment of the OWL language as both a schema and inference language. This enables a large number of complex constraints to be expressed in a wide variety of different ways. For most users, simple class hierarchies and properties are more than enough for their data modelling requires, but for advanced users who wish to build complex business rules into their data flows, there is no substitute for pure logical axiom writing in OWL. Read More .",
    "url": "/docs/user-guide/schema",
    "relUrl": "/user-guide/schema"
  }
  ,"49": {
    "title": "Simple Query",
    "content": "Simple Query . . Introduction - Rule 1. Triples all the way down | Rule 2 Unify All The Things WOQL Variables | Logical Operators | | That’s not all folks | | Introduction - . While WOQL is a very powerful and sophisticated query language which allows you to concisely express very complex patterns over arbitrary data structures. However, what makes it so expressive and easy to use is the radical simplicity of the core underlying concepts. . To unleash the power of WOQL, you just need to understand two very simple things. . Rule 1. Triples all the way down . In Terminus DB every single fragment of information is always and universally stored and accessible as triples. Triples are the universal and fundamental atom of information in TerminusDB - objects and documents and everything else is stored as collections of triples and it is always possible to break any object down in a reliable and deterministic way into a precise set of triples. Not only that, but TerminusDB adheres to the RDF standard, which means all triples have a regular structure and interpretation and strong norms. From a query writer point of view, this regularity is very helpful - you don’t have to care about the low-level structure of the data (what table it is stored in, how many columns there, etc), you just have to care about the patterns of meaning you are interested in. . (table about Triples) . Simple Add Triple Queries . Rule 2 Unify All The Things . The second fundamental concept behind WOQL is unification. This is an old computer science concept that has been polished and refined for 60 years and is defined in obscure mathematical jargon, but it is remarkably simple and intuitive to understand by example. . WOQL Variables . In WOQL we have the concept of variables, which are normally represented by a string that starts with v: - we use them to store the results of queries. For example we might define variables like ‘v:First Name’ , ‘v:Family Name’, ‘v:Date of Birth’ for a query to find somebody’s basic identifying information. . If we use a variable in a triple query, TerminusDB will show us every possible value that exists in the database that could possibly fill that variable in that position in the query. . Table showing all combinations of triple variable pattern matches on our simple database. . Logical Operators . Single triple pattern matching like the above, is certainly neat, but there’s a limited number of things that can be expressed as a single pattern of triples, even with all our variables turned on. However, WOQL also provides logical operators, AND, OR which allow you to combine as many basic patterns as you like into incredibly expressive queries in very simple forms. . The most useful operator is logical AND - WOQL.and() which behaves as we would logically expect - if all of the patterns defined within a WOQL.and() can be filled by the database, all of the results will be returned, otherwise, no results will be returned. . The other basic logical operators: OR - WOQL.or() and NOT - WOQL.not() are also very useful - they are interpreted also as expected, - in the first case, the query will return the first result that it matches in a list of possibilities, in the second case, the query will only return true if the pattern specified is not found in the database. . Below are some simple examples of using these logical operators in practice. It is amazing how many things you can readily express simply by combining these patterns in different ways. Extreme simplicity and absolutely regularity in the little things allows extreme elegance of description in the big things. . That’s not all folks . One other huge advantage of a simple and regular underlying architecture is that it becomes much easier to build extra functionality on top. In addition to the basic ideas presented here, WOQL also has a broad set of built in operators and libraries which cover arithmetic, mathematical, date and time, taxonomy specific patterns, aggregation, ordering, grouping, geographical and a wide range of other functions out of the box. This allows you to move a lot of your logic into the Database Layer and out of your application code - the database should be the only thing that cares about the structure of the storage layer, the rest of us care about getting the data we want out! . The rest of this chapter contains lots of information about all the functions and operators that WOQL provides and how you can access them, but before you leave, we have a question to ask. . I want to ask my database for the full records of all living people whose direct ancestors were born in Italy before 1850 (assuming I have the records of course) along with their lineage. . In WOQL my query would look like this: . WOQL.(&quot;v:Living Person Record ID&quot;, &quot;status&quot;, &quot;alive&quot;) .path(&quot;v:Living Person Record ID&quot;, &quot;parent+&quot;, &quot;v:Italian Ancestor&quot;, &quot;v:Ancestry Line&quot;) .triple(&quot;v:Italian Ancestor&quot;, &quot;date_born&quot;, &quot;v:Date of Birth&quot;) .less(&quot;v:Date of Birth&quot;, 1850) .triple(&quot;v:Italian Ancestor&quot;, &quot;country_born&quot;, &quot;Italy&quot;) .get_object(&quot;v:Living Person Record ID&quot;, &quot;v:Full Record&quot;) . How would you ask your database this question? . How .",
    "url": "/docs/user-guide/query/simple-query/",
    "relUrl": "/user-guide/query/simple-query/"
  }
  ,"50": {
    "title": "Getting started tutorials",
    "content": "Getting started tutorials . In here you will see a step-by-step guide to create your first knowledge with Terminus DB. We will cover how to do it with console (using WOQLjs) and with the Python Client. .",
    "url": "/docs/getting-started/start-tutorials",
    "relUrl": "/getting-started/start-tutorials"
  }
  ,"51": {
    "title": "Table View",
    "content": "Table View . This section covers all of the rules which can be applied to a table view. As mentioned in previous section a table view can be defined as shown below: . view = View.table() . All other rules are accessible as chaining functions of variable view. . . 1) column_order . column_order helps to arrange columns based on whatever order is specified, columns are accesed by header names. This function also hides column names which are not mentioned as arguments in the function . view.table().column_order(&quot;c&quot;, &quot;b&quot;, &quot;d&quot;) . 2) column . You can refer to a column using its header name . view.column(&#39;c&#39;) . 3) header . Renames a particular column to another name . view.column(&#39;c&#39;).header(&#39;New Name&#39;) . 4) header . Renames a particular column to another name . view.column(&#39;c&#39;).header(&#39;New Name&#39;) . 5) pager . on set to true allows paging in table . view.pager(true) . 5) changeSize . Allows to change table page size . view.changeSize(true) . 5) pager . on set to true allows pagination . view.pager(true) . 6) pageSize . Defines minimum page size of a table . view.pagesize(10) // displays only 10 rows per page .",
    "url": "/docs/user-guide/visualisation/table/",
    "relUrl": "/user-guide/visualisation/table/"
  }
  ,"52": {
    "title": "Time Travel",
    "content": "Time Travel . . Script that Creates the Examples Sequence of WOQL queries as a script | | Using the commit graph to create time travel | Time Traveling with the TerminusDB API | The WOQL Time Travel Library | getFirstCommit(cresource) | getCommitProperties Compounding Version 1: | Get Commit Child On Branch | loadBranchDetails(branch) | loadActiveCommitAtTime(ts, branch) | | The WOQL Time Travel Console | Use Cases 1. updating of numbers in a bank a/c | 2. machine learning use case | | . Script that Creates the Examples . Script that Creates the Examples below . Sequence of WOQL queries as a script . Sequence of WOQL queries that updates new WOQL database and populates the commit graph with all the commits necessary to illustrate all of the examples in the sections. . . Using the commit graph to create time travel . Using the commit graph for time travel queries . simply put down the technique for using time stamps and commit chaining to find the active commit at any point in time. . . Time Traveling with the TerminusDB API . here is how you change the api endpoint to affect time travel . . The WOQL Time Travel Library . 6 key queries &lt;- explain them . getFirstCommit(cresource) . Gives you the first commit in the database . returns [Tail: IRI of first commit, CommitID: ID of first commit] . WOQLLibrary.prototype.getFirstCommit = function(cresource) { cresource= cresource || this.commits new WOQLQuery().using(cresource).and( new WOQLQuery().triple(‘v:Tail’, ‘ref:commit_id’, “v:CommitID”), new WOQLQuery().not().triple(‘v:Tail’, ‘ref:commit_parent’, ‘v:Any’), ) } . Explanation - there is only single commit in the graph that does not have a parent - it is the first commit. . getCommitProperties . WOQLLibrary.prototype.getCommitProperties = function(commit_id, cresource) { cresource= cresource || this.commits let woql = new WOQLQuery().using(cresource).and( new WOQLQuery().eq(&quot;v:CommitID&quot;, commit_id), new WOQLQuery().triple(&quot;v:CommitIRI&quot;, &#39;ref:commit_id&#39;, commit_id), new WOQLQuery().triple(&quot;v:CommitIRI&quot;, &#39;ref:commit_timestamp&#39;, &#39;v:Time&#39;), new WOQLQuery().opt().triple(&quot;v:CommitIRI&quot;, &#39;ref:commit_author&#39;, &#39;v:Author&#39;), new WOQLQuery().opt().triple(&quot;v:CommitIRI&quot;, &#39;ref:commit_message&#39;, &#39;v:Message&#39;), new WOQLQuery() .opt() .and( new WOQLQuery().triple(&quot;v:CommitIRI&quot;, &#39;ref:commit_parent&#39;, &#39;v:ParentIRI&#39;), new WOQLQuery().triple(&#39;v:ParentIRI&#39;, &#39;ref:commit_id&#39;, &#39;v:Parent&#39;), ), new WOQLQuery() .opt() .select(&quot;v:Children&quot;) .group_by(&#39;v:ChildID&#39;, &#39;v:Child&#39;, &#39;v:Children&#39;) .and( new WOQLQuery().triple(&#39;v:ChildID&#39;, &#39;ref:commit_parent&#39;, commitvar), new WOQLQuery().triple(&#39;v:ChildID&#39;, &#39;ref:commit_id&#39;, &#39;v:Child&#39;), ), new WOQLQuery() .opt() .and( new WOQLQuery().triple(&#39;v:BranchIRI&#39;, &#39;ref:branch_name&#39;, &#39;v:Branch&#39;), new WOQLQuery().triple(&#39;v:BranchIRI&#39;, &#39;ref:ref_commit&#39;, commitvar), ), ) return woql } . Branch, Message, Time, Author, Children, Parent, Branch . Gets all possible metadata about a specific commit and loads it into a single binding with the following fields: . (note this is fast because we consider the commit in isolation without the branch context and do not have to traverse any relationships) . Compounding Version 1: . WOQL.lib().getFirstCommit().and().lib().getCommitProperties() . Get Commit Child On Branch . getChildOnBranch(commit_id, branch){ new WOQLQuery().and( new WOQLQuery().triple(&#39;v:Branch&#39;, &#39;ref:branch_name&#39;, branch), new WOQLQuery().triple(&#39;v:Branch&#39;, &#39;ref:ref_commit&#39;, &#39;v:BHead&#39;), new WOQLQuery().path(&#39;v:BHead&#39;, &#39;ref:commit_parent+&#39;, &#39;v:ChildIRI&#39;, &#39;v:Path&#39;), new WOQLQuery().triple(&#39;v:CommitIRI&#39;, &#39;ref:commit_parent&#39;, &quot;v:ChildIRI&quot;), new WOQLQuery().triple(&#39;v:CommitIRI&#39;, &#39;ref:commit_id&#39;, commit_id), new WOQLQuery().triple(&#39;v:ChildIRI&#39;, &#39;ref:commit_id&#39;, &quot;v:CommitID&quot;), ) } . loadBranchDetails(branch) . let woql = new WOQLQuery().and( new WOQLQuery().triple(&#39;v:BranchIRI&#39;, &#39;ref:branch_name&#39;, branch), new WOQLQuery() .opt() .and( new WOQLQuery().triple(&#39;v:BranchIRI&#39;, &#39;ref:ref_commit&#39;, &#39;v:HeadIRI&#39;), new WOQLQuery().triple(&#39;v:HeadIRI&#39;, &#39;ref:commit_id&#39;, head), new WOQLQuery().triple(&#39;v:HeadIRI&#39;, &#39;ref:commit_timestamp&#39;, &#39;v:Time&#39;), ), ) . Returns the name of a branch and the time of the last commit to head of that branch . This is important because this tells you if somebody has advance head while you were doing something else. . loadActiveCommitAtTime(ts, branch) . WOQLQuery() .limit(1) .or( new WOQLQuery().and( new WOQLQuery().not().greater(&#39;v:LastCommitBefore&#39;, &#39;v:HeadTime&#39;), new WOQLQuery().eq(&#39;v:CommitID&#39;, &#39;v:HeadID&#39;), ), new WOQLQuery() .limit(1) .and( new WOQLQuery().path(&#39;v:Head&#39;, &#39;ref:commit_parent+&#39;, &#39;v:Tail&#39;, &#39;v:Path&#39;), new WOQLQuery().triple(&#39;v:Tail&#39;, &#39;ref:commit_id&#39;, &#39;v:TailID&#39;), new WOQLQuery().triple(&#39;v:Tail&#39;, &#39;ref:commit_timestamp&#39;, &#39;v:TailTime&#39;), new WOQLQuery().not().greater(&#39;v:LastCommitBefore&#39;, &#39;v:TailTime&#39;), new WOQLQuery().eq(&#39;v:CommitID&#39;, &#39;v:TailID&#39;), ), ), ) . 6 key queries &lt;- explain them . /** * pass the client and uses looks for current branch in current commits graph */ WOQLLibrary.prototype.loadBranchGraphNames = function(branch) { return this.getBranchGraphNames(branch, this.commits) } /** * Loads meta-data about the types of graphs that existed in a DB at the time of a particular commit */ WOQLLibrary.prototype.getGraphsAtRef = function(commitID, cresource) { let woql = new WOQLQuery().and( new WOQLQuery().triple(&#39;v:CommitIRI&#39;, &#39;ref:commit_id&#39;, commitID), new WOQLQuery().or( new WOQLQuery() .triple(&#39;v:CommitIRI&#39;, &#39;ref:instance&#39;, &#39;v:GraphIRI&#39;) .eq(&#39;v:GraphType&#39;, &#39;instance&#39;), new WOQLQuery() .triple(&#39;v:CommitIRI&#39;, &#39;ref:schema&#39;, &#39;v:GraphIRI&#39;) .eq(&#39;v:GraphType&#39;, &#39;schema&#39;), new WOQLQuery() .triple(&#39;v:CommitIRI&#39;, &#39;ref:inference&#39;, &#39;v:GraphIRI&#39;) .eq(&#39;v:GraphType&#39;, &#39;inference&#39;), ), new WOQLQuery().triple(&#39;v:GraphIRI&#39;, &#39;ref:graph_name&#39;, &#39;v:GraphID&#39;), ) return this.pointQueryAtResource(woql, cresource) } WOQLLibrary.prototype.loadGraphsAtRef = function(ref) { return this.getGraphsAtRef(ref, client.commits) } WOQLLibrary.prototype.loadGraphStructure = function(branch, ref) { return this.getGraphStructure(branch, ref, client.commits) } /** * Loads the branches, graphs in those branches and their sizes for any given ref / branch */ WOQLLibrary.prototype.getGraphStructure = function(branch, ref, cresource) { if (ref) { var start = this.getGraphsAtRef(ref) } else { var start = this.getBranchGraphNames(branch) } let commitquery = new WOQLQuery().and(start, new WOQLQuery().opt(this.getFirstCommit())) return this.pointQueryAtResource(commitquery, cresource) let full = new WOQLQuery().and( new WOQLQuery().using(cresource, commitquery), new WOQLQuery().and( new WOQLQuery().concat(&#39;v:GraphType/v:GraphID&#39;, &#39;v:GraphFilter&#39;), new WOQLQuery().size(&#39;v:GraphFilter&#39;, &#39;v:Size&#39;), new WOQLQuery().triple_count(&#39;v:GraphFilter&#39;, &#39;v:Triples&#39;), ), ) return full } . The WOQL Time Travel Console . . Use Cases . 1. updating of numbers in a bank a/c . rewinding to a point in time to see who the author of the last commit at a specific time . 2. machine learning use case . Idea: Compare predictions result changes when deploying new models . simplest possible labour saving device for preventing reloading of data in machine learning pipeline .",
    "url": "/docs/user-guide/revision-control/time-travel/",
    "relUrl": "/user-guide/revision-control/time-travel/"
  }
  ,"53": {
    "title": "Tutorials",
    "content": "Tutorials . Here are a list of tutorials that shows what TerminusDB can do. . . Tutorials My First TerminusDB Graph Visualisation — Bike Share Data | TerminusDB graph visualisation of Dublin Council voting data | Loading your local files in TerminusDB | Loading data in turtle RDF format to TerminusDB | Demos and tutorials provided by Chrisjhorn | | . My First TerminusDB Graph Visualisation — Bike Share Data . In this tutorial, we will start using TerminusDB and its query client — WOQL.js — to quickly build a database and a schema; import and organise data; create a visualisation; and plug it in to your website. . Go to tutorial . . TerminusDB graph visualisation of Dublin Council voting data . In this tutorial, we will use TerminusDB to show you how to analyse the voting behavior of politicians. . Go to tutorial . . Loading your local files in TerminusDB . Answer one of the most common questions: how to load a local CSV in the hard drive into your TerminusDB running in a local docker container. . Go to tutorial . . Loading data in turtle RDF format to TerminusDB . Loading data in turtle RDF format to TerminusDB is elegant and simple. In this tutorial we will show you how. . Go to tutorial . . Demos and tutorials provided by Chrisjhorn . Some contributed tutorial and example software in Python to the TerminusDB open source graph base. . Go to GitHub repo .",
    "url": "/docs/getting-started/tutorials/",
    "relUrl": "/getting-started/tutorials/"
  }
  ,"54": {
    "title": "Visualisation",
    "content": "Visualization . . Visualization | Here we can define different views on attained results after firing woql queries. We take the help of Terminus View and rules provided here to alter the results according to whatever we want to see. . The different views made available are - 1) Table View 2) Graph View 3) Chooser View 4) Document Frames View . Under the hood a view is defined as new TerminusView which is accessed at the console via a variable names View. In other words View represents a new TerminusView . Example: . view = View.table() // is a view which displays results in table format . or . view = View.graph() // is a view which displays results in graph format .",
    "url": "/docs/user-guide/visualisation",
    "relUrl": "/user-guide/visualisation"
  }
  ,"55": {
    "title": "WOQL Standard Library",
    "content": "WOQL Standard Library . .",
    "url": "/docs/user-guide/query/woql-lib/",
    "relUrl": "/user-guide/query/woql-lib/"
  }
  
}